#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
<!-- HTML header for doxygen 1.9.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ResilientDB: 05_relevantcontentfilter</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen_html_style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../logo.png"/></td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('d2/d40/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_205__relevantcontentfilter.html','../../'); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">05_relevantcontentfilter</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="autotoc_md1422"></a>
autotoc_md1422</h2>
<p>layout: default title: "RelevantContentFilter" parent: "Crawl4AI" </p>
<h2><a class="anchor" id="autotoc_md1423"></a>
nav_order: 5</h2>
<h1><a class="anchor" id="autotoc_md1424"></a>
Chapter 5: Focusing on What Matters - RelevantContentFilter</h1>
<p>In <a class="el" href="../../df/d80/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_204__contentscrapingstrategy.html">Chapter 4: Cleaning Up the Mess - ContentScrapingStrategy</a>, we learned how Crawl4AI takes the raw, messy HTML from a webpage and cleans it up using a <code>ContentScrapingStrategy</code>. This gives us a tidier version of the HTML (<code>cleaned_html</code>) and extracts basic elements like links and images.</p>
<p>But even after this initial cleanup, the page might still contain a lot of "noise" relative to what we <em>actually</em> care about. Imagine a news article page: the <code>ContentScrapingStrategy</code> might remove scripts and styles, but it could still leave the main article text, plus related article links, user comments, sidebars with ads, and maybe a lengthy footer.</p>
<p>If our goal is just to get the main article content (e.g., to summarize it or feed it to an AI), all that extra stuff is just noise. How can we filter the cleaned content even further to keep only the truly relevant parts?</p>
<h2><a class="anchor" id="autotoc_md1425"></a>
What Problem Does <code>RelevantContentFilter</code> Solve?</h2>
<p>Think of the <code>cleaned_html</code> from the previous step like flour that's been roughly sifted â€“ the biggest lumps are gone, but there might still be smaller clumps or bran mixed in. If you want super fine flour for a delicate cake, you need a finer sieve.</p>
<p><code>RelevantContentFilter</code> acts as this <b>finer sieve</b> or a <b>Relevance Sieve</b>. It's a strategy applied <em>after</em> the initial cleaning by <code>ContentScrapingStrategy</code> but <em>before</em> the final processing (like generating the final Markdown output or using an AI for extraction). Its job is to go through the cleaned content and decide which parts are truly relevant to our goal, removing the rest.</p>
<p>This helps us:</p>
<ol type="1">
<li><b>Reduce Noise:</b> Eliminate irrelevant sections like comments, footers, navigation bars, or tangential "related content" blocks.</li>
<li><b>Focus AI:</b> If we're sending the content to a Large Language Model (LLM), feeding it only the most relevant parts saves processing time (and potentially money) and can lead to better results.</li>
<li><b>Improve Accuracy:</b> By removing distracting noise, subsequent steps like data extraction are less likely to grab the wrong information.</li>
</ol>
<h2><a class="anchor" id="autotoc_md1426"></a>
What is <code>RelevantContentFilter</code>?</h2>
<p><code>RelevantContentFilter</code> is an abstract concept (a blueprint) in Crawl4AI representing a <b>method for identifying and retaining only the relevant portions of cleaned HTML content</b>. It defines <em>that</em> we need a way to filter for relevance, but the specific technique used can vary.</p>
<p>This allows us to choose different filtering approaches depending on the task and the type of content.</p>
<h2><a class="anchor" id="autotoc_md1427"></a>
The Different Filters: Tools for Sieving</h2>
<p>Crawl4AI provides several concrete implementations (the actual sieves) of <code>RelevantContentFilter</code>:</p>
<ol type="1">
<li><b><code>BM25ContentFilter</code> (The Keyword Sieve):</b><ul>
<li><b>Analogy:</b> Like a mini search engine operating <em>within</em> the webpage.</li>
<li><b>How it Works:</b> You give it (or it figures out) some keywords related to what you're looking for (e.g., from a user query like "product specifications" or derived from the page title). It then uses a search algorithm called BM25 to score different chunks of the cleaned HTML based on how relevant they are to those keywords. Only the chunks scoring above a certain threshold are kept.</li>
<li><b>Good For:</b> Finding specific sections about a known topic within a larger page (e.g., finding only the paragraphs discussing "climate change impact" on a long environmental report page).</li>
</ul>
</li>
<li><b><code>PruningContentFilter</code> (The Structural Sieve):</b><ul>
<li><b>Analogy:</b> Like a gardener pruning a bush, removing weak or unnecessary branches based on their structure.</li>
<li><b>How it Works:</b> This filter doesn't care about keywords. Instead, it looks at the <em>structure</em> and <em>characteristics</em> of the HTML elements. It removes elements that often represent noise, such as those with very little text compared to the number of links (low text density), elements with common "noise" words in their CSS classes or IDs (like <code>sidebar</code>, <code>comments</code>, <code>footer</code>), or elements deemed structurally insignificant.</li>
<li><b>Good For:</b> Removing common boilerplate sections (like headers, footers, simple sidebars, navigation) based purely on layout and density clues, even if you don't have a specific topic query.</li>
</ul>
</li>
<li><b><code>LLMContentFilter</code> (The AI Sieve):</b><ul>
<li><b>Analogy:</b> Asking a smart assistant to read the cleaned content and pick out only the parts relevant to your request.</li>
<li><b>How it Works:</b> This filter sends the cleaned HTML (often broken into manageable chunks) to a Large Language Model (like GPT). You provide an instruction (e.g., "Extract only the main article content, removing all comments and related links" or "Keep only the sections discussing financial results"). The AI uses its understanding of language and context to identify and return only the relevant parts, often already formatted nicely (like in Markdown).</li>
<li><b>Good For:</b> Handling complex relevance decisions that require understanding meaning and context, following nuanced natural language instructions. (Note: Requires configuring LLM access, like API keys, and can be slower and potentially costlier than other methods).</li>
</ul>
</li>
</ol>
<h2><a class="anchor" id="autotoc_md1428"></a>
How <code>RelevantContentFilter</code> is Used (Via Markdown Generation)</h2>
<p>In Crawl4AI, the <code>RelevantContentFilter</code> is typically integrated into the <b>Markdown generation</b> step. The standard markdown generator (<code>DefaultMarkdownGenerator</code>) can accept a <code>RelevantContentFilter</code> instance.</p>
<p>When configured this way:</p>
<ol type="1">
<li>The <code>AsyncWebCrawler</code> fetches the page and uses the <code>ContentScrapingStrategy</code> to get <code>cleaned_html</code>.</li>
<li>It then calls the <code>DefaultMarkdownGenerator</code> to produce the Markdown output.</li>
<li>The generator first creates the standard, "raw" Markdown from the <em>entire</em> <code>cleaned_html</code>.</li>
<li><b>If</b> a <code>RelevantContentFilter</code> was provided to the generator, it then uses this filter on the <code>cleaned_html</code> to select only the relevant HTML fragments.</li>
<li>It converts <em>these filtered fragments</em> into Markdown. This becomes the <code>fit_markdown</code>.</li>
</ol>
<p>So, the <code>CrawlResult</code> will contain <em>both</em>:</p><ul>
<li><code>result.markdown.raw_markdown</code>: Markdown based on the full <code>cleaned_html</code>.</li>
<li><code>result.markdown.fit_markdown</code>: Markdown based <em>only</em> on the parts deemed relevant by the filter.</li>
</ul>
<p>Let's see how to configure this.</p>
<h3><a class="anchor" id="autotoc_md1429"></a>
Example 1: Using <code>BM25ContentFilter</code> to find specific content</h3>
<p>Imagine we crawled a page about renewable energy, but we only want the parts specifically discussing <b>solar power</b>.</p>
<div class="fragment"><div class="line"><span class="comment"># chapter5_example_1.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> (</div>
<div class="line">    AsyncWebCrawler,</div>
<div class="line">    CrawlerRunConfig,</div>
<div class="line">    DefaultMarkdownGenerator, <span class="comment"># The standard markdown generator</span></div>
<div class="line">    BM25ContentFilter         <span class="comment"># The keyword-based filter</span></div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="comment"># 1. Create the BM25 filter with our query</span></div>
<div class="line">    solar_filter = BM25ContentFilter(user_query=<span class="stringliteral">&quot;solar power technology&quot;</span>)</div>
<div class="line">    print(f<span class="stringliteral">&quot;Filter created for query: &#39;{solar_filter.user_query}&#39;&quot;</span>)</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 2. Create a Markdown generator that USES this filter</span></div>
<div class="line">    markdown_generator_with_filter = DefaultMarkdownGenerator(</div>
<div class="line">        content_filter=solar_filter</div>
<div class="line">    )</div>
<div class="line">    print(<span class="stringliteral">&quot;Markdown generator configured with BM25 filter.&quot;</span>)</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 3. Create CrawlerRunConfig using this specific markdown generator</span></div>
<div class="line">    run_config = CrawlerRunConfig(</div>
<div class="line">        markdown_generator=markdown_generator_with_filter</div>
<div class="line">    )</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 4. Run the crawl</span></div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        <span class="comment"># Example URL (replace with a real page having relevant content)</span></div>
<div class="line">        url_to_crawl = <span class="stringliteral">&quot;https://en.wikipedia.org/wiki/Renewable_energy&quot;</span></div>
<div class="line">        print(f<span class="stringliteral">&quot;\nCrawling {url_to_crawl}...&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        result = await crawler.arun(url=url_to_crawl, config=run_config)</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> result.success:</div>
<div class="line">            print(<span class="stringliteral">&quot;\nCrawl successful!&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;Raw Markdown length: {len(result.markdown.raw_markdown)}&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;Fit Markdown length: {len(result.markdown.fit_markdown)}&quot;</span>)</div>
<div class="line"> </div>
<div class="line">            <span class="comment"># The fit_markdown should be shorter and focused on solar power</span></div>
<div class="line">            print(<span class="stringliteral">&quot;\n--- Start of Fit Markdown (Solar Power Focus) ---&quot;</span>)</div>
<div class="line">            <span class="comment"># Print first 500 chars of the filtered markdown</span></div>
<div class="line">            print(result.markdown.fit_markdown[:500] + <span class="stringliteral">&quot;...&quot;</span>)</div>
<div class="line">            print(<span class="stringliteral">&quot;--- End of Fit Markdown Snippet ---&quot;</span>)</div>
<div class="line">        <span class="keywordflow">else</span>:</div>
<div class="line">            print(f<span class="stringliteral">&quot;\nCrawl failed: {result.error_message}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
<div class="ttc" id="anamespacemain_html"><div class="ttname"><a href="../../d2/dc1/namespacemain.html">main</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/dba/main_8py_source.html#l00001">main.py:1</a></div></div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ol type="1">
<li><b>Create Filter:</b> We make an instance of <code>BM25ContentFilter</code>, telling it we're interested in "solar power technology".</li>
<li><b>Create Generator:</b> We make an instance of <code>DefaultMarkdownGenerator</code> and pass our <code>solar_filter</code> to its <code>content_filter</code> parameter.</li>
<li><b>Configure Run:</b> We create <code>CrawlerRunConfig</code> and tell it to use our special <code>markdown_generator_with_filter</code> for this run.</li>
<li><b>Crawl &amp; Check:</b> We run the crawl as usual. In the <code>result</code>, <code>result.markdown.raw_markdown</code> will have the markdown for the whole page, while <code>result.markdown.fit_markdown</code> will <em>only</em> contain markdown derived from the HTML parts that the <code>BM25ContentFilter</code> scored highly for relevance to "solar power technology". You'll likely see the <code>fit_markdown</code> is significantly shorter.</li>
</ol>
<h3><a class="anchor" id="autotoc_md1430"></a>
Example 2: Using <code>PruningContentFilter</code> to remove boilerplate</h3>
<p>Now, let's try removing common noise like sidebars or footers based on structure, without needing a specific query.</p>
<div class="fragment"><div class="line"><span class="comment"># chapter5_example_2.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> (</div>
<div class="line">    AsyncWebCrawler,</div>
<div class="line">    CrawlerRunConfig,</div>
<div class="line">    DefaultMarkdownGenerator,</div>
<div class="line">    PruningContentFilter <span class="comment"># The structural filter</span></div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="comment"># 1. Create the Pruning filter (no query needed)</span></div>
<div class="line">    pruning_filter = PruningContentFilter()</div>
<div class="line">    print(<span class="stringliteral">&quot;Filter created: PruningContentFilter (structural)&quot;</span>)</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 2. Create a Markdown generator that uses this filter</span></div>
<div class="line">    markdown_generator_with_filter = DefaultMarkdownGenerator(</div>
<div class="line">        content_filter=pruning_filter</div>
<div class="line">    )</div>
<div class="line">    print(<span class="stringliteral">&quot;Markdown generator configured with Pruning filter.&quot;</span>)</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 3. Create CrawlerRunConfig using this generator</span></div>
<div class="line">    run_config = CrawlerRunConfig(</div>
<div class="line">        markdown_generator=markdown_generator_with_filter</div>
<div class="line">    )</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 4. Run the crawl</span></div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        <span class="comment"># Example URL (replace with a real page that has boilerplate)</span></div>
<div class="line">        url_to_crawl = <span class="stringliteral">&quot;https://www.python.org/&quot;</span> <span class="comment"># Python homepage likely has headers/footers</span></div>
<div class="line">        print(f<span class="stringliteral">&quot;\nCrawling {url_to_crawl}...&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        result = await crawler.arun(url=url_to_crawl, config=run_config)</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> result.success:</div>
<div class="line">            print(<span class="stringliteral">&quot;\nCrawl successful!&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;Raw Markdown length: {len(result.markdown.raw_markdown)}&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;Fit Markdown length: {len(result.markdown.fit_markdown)}&quot;</span>)</div>
<div class="line"> </div>
<div class="line">            <span class="comment"># fit_markdown should have less header/footer/sidebar content</span></div>
<div class="line">            print(<span class="stringliteral">&quot;\n--- Start of Fit Markdown (Pruned) ---&quot;</span>)</div>
<div class="line">            print(result.markdown.fit_markdown[:500] + <span class="stringliteral">&quot;...&quot;</span>)</div>
<div class="line">            print(<span class="stringliteral">&quot;--- End of Fit Markdown Snippet ---&quot;</span>)</div>
<div class="line">        <span class="keywordflow">else</span>:</div>
<div class="line">            print(f<span class="stringliteral">&quot;\nCrawl failed: {result.error_message}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<p>The structure is the same as the BM25 example, but:</p>
<ol type="1">
<li>We instantiate <code>PruningContentFilter()</code>, which doesn't require a <code>user_query</code>.</li>
<li>We pass this filter to the <code>DefaultMarkdownGenerator</code>.</li>
<li>The resulting <code>result.markdown.fit_markdown</code> should contain Markdown primarily from the main content areas of the page, with structurally identified boilerplate removed.</li>
</ol>
<h3><a class="anchor" id="autotoc_md1431"></a>
Example 3: Using <code>LLMContentFilter</code> (Conceptual)</h3>
<p>Using <code>LLMContentFilter</code> follows the same pattern, but requires setting up LLM provider details.</p>
<div class="fragment"><div class="line"><span class="comment"># chapter5_example_3_conceptual.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> (</div>
<div class="line">    AsyncWebCrawler,</div>
<div class="line">    CrawlerRunConfig,</div>
<div class="line">    DefaultMarkdownGenerator,</div>
<div class="line">    LLMContentFilter,</div>
<div class="line">    <span class="comment"># Assume LlmConfig is set up correctly (see LLM-specific docs)</span></div>
<div class="line">    <span class="comment"># from crawl4ai.async_configs import LlmConfig</span></div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Assume llm_config is properly configured with API keys, provider, etc.</span></div>
<div class="line"><span class="comment"># Example: llm_config = LlmConfig(provider=&quot;openai&quot;, api_token=&quot;env:OPENAI_API_KEY&quot;)</span></div>
<div class="line"><span class="comment"># For this example, we&#39;ll pretend it&#39;s ready.</span></div>
<div class="line"><span class="keyword">class </span>MockLlmConfig: <span class="comment"># Mock for demonstration</span></div>
<div class="line">    provider = <span class="stringliteral">&quot;mock_provider&quot;</span></div>
<div class="line">    api_token = <span class="stringliteral">&quot;mock_token&quot;</span></div>
<div class="line">    base_url = <span class="keywordtype">None</span></div>
<div class="line">llm_config = MockLlmConfig()</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="comment"># 1. Create the LLM filter with an instruction</span></div>
<div class="line">    instruction = <span class="stringliteral">&quot;Extract only the main news article content. Remove headers, footers, ads, comments, and related links.&quot;</span></div>
<div class="line">    llm_filter = LLMContentFilter(</div>
<div class="line">        instruction=instruction,</div>
<div class="line">        llmConfig=llm_config <span class="comment"># Pass the LLM configuration</span></div>
<div class="line">    )</div>
<div class="line">    print(f<span class="stringliteral">&quot;Filter created: LLMContentFilter&quot;</span>)</div>
<div class="line">    print(f<span class="stringliteral">&quot;Instruction: &#39;{llm_filter.instruction}&#39;&quot;</span>)</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 2. Create a Markdown generator using this filter</span></div>
<div class="line">    markdown_generator_with_filter = DefaultMarkdownGenerator(</div>
<div class="line">        content_filter=llm_filter</div>
<div class="line">    )</div>
<div class="line">    print(<span class="stringliteral">&quot;Markdown generator configured with LLM filter.&quot;</span>)</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 3. Create CrawlerRunConfig</span></div>
<div class="line">    run_config = CrawlerRunConfig(</div>
<div class="line">        markdown_generator=markdown_generator_with_filter</div>
<div class="line">    )</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 4. Run the crawl</span></div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        <span class="comment"># Example URL (replace with a real news article)</span></div>
<div class="line">        url_to_crawl = <span class="stringliteral">&quot;https://httpbin.org/html&quot;</span> <span class="comment"># Using simple page for demo</span></div>
<div class="line">        print(f<span class="stringliteral">&quot;\nCrawling {url_to_crawl}...&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># In a real scenario, this would call the LLM API</span></div>
<div class="line">        result = await crawler.arun(url=url_to_crawl, config=run_config)</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> result.success:</div>
<div class="line">            print(<span class="stringliteral">&quot;\nCrawl successful!&quot;</span>)</div>
<div class="line">            <span class="comment"># The fit_markdown would contain the AI-filtered content</span></div>
<div class="line">            print(<span class="stringliteral">&quot;\n--- Start of Fit Markdown (AI Filtered - Conceptual) ---&quot;</span>)</div>
<div class="line">            <span class="comment"># Because we used a mock LLM/simple page, fit_markdown might be empty or simple.</span></div>
<div class="line">            <span class="comment"># On a real page with a real LLM, it would ideally contain just the main article.</span></div>
<div class="line">            print(result.markdown.fit_markdown[:500] + <span class="stringliteral">&quot;...&quot;</span>)</div>
<div class="line">            print(<span class="stringliteral">&quot;--- End of Fit Markdown Snippet ---&quot;</span>)</div>
<div class="line">        <span class="keywordflow">else</span>:</div>
<div class="line">            print(f<span class="stringliteral">&quot;\nCrawl failed: {result.error_message}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ol type="1">
<li>We create <code>LLMContentFilter</code>, providing our natural language <code>instruction</code> and the necessary <code>llmConfig</code> (which holds provider details and API keys - mocked here for simplicity).</li>
<li>We integrate it into <code>DefaultMarkdownGenerator</code> and <code>CrawlerRunConfig</code> as before.</li>
<li>When <code>arun</code> is called, the <code>LLMContentFilter</code> would (in a real scenario) interact with the configured LLM API, sending chunks of the <code>cleaned_html</code> and the instruction, then assembling the AI's response into the <code>fit_markdown</code>.</li>
</ol>
<h2><a class="anchor" id="autotoc_md1432"></a>
Under the Hood: How Filtering Fits In</h2>
<p>The <code>RelevantContentFilter</code> doesn't run on its own; it's invoked by another component, typically the <code>DefaultMarkdownGenerator</code>.</p>
<p>Here's the sequence:</p>
<div class="fragment"><div class="line">sequenceDiagram</div>
<div class="line">    participant User</div>
<div class="line">    participant AWC as AsyncWebCrawler</div>
<div class="line">    participant Config as CrawlerRunConfig</div>
<div class="line">    participant Scraper as ContentScrapingStrategy</div>
<div class="line">    participant MDGen as DefaultMarkdownGenerator</div>
<div class="line">    participant Filter as RelevantContentFilter</div>
<div class="line">    participant Result as CrawlResult</div>
<div class="line"> </div>
<div class="line">    User-&gt;&gt;AWC: arun(url, config=my_config)</div>
<div class="line">    Note over AWC: Config includes Markdown Generator with a Filter</div>
<div class="line">    AWC-&gt;&gt;Scraper: scrap(raw_html)</div>
<div class="line">    Scraper--&gt;&gt;AWC: cleaned_html, links, etc.</div>
<div class="line">    AWC-&gt;&gt;MDGen: generate_markdown(cleaned_html, config=my_config)</div>
<div class="line">    Note over MDGen: Uses html2text for raw markdown</div>
<div class="line">    MDGen--&gt;&gt;MDGen: raw_markdown = html2text(cleaned_html)</div>
<div class="line">    Note over MDGen: Now, check for content_filter</div>
<div class="line">    alt Filter Provided in MDGen</div>
<div class="line">        MDGen-&gt;&gt;Filter: filter_content(cleaned_html)</div>
<div class="line">        Filter--&gt;&gt;MDGen: filtered_html_fragments</div>
<div class="line">        Note over MDGen: Uses html2text on filtered fragments</div>
<div class="line">        MDGen--&gt;&gt;MDGen: fit_markdown = html2text(filtered_html_fragments)</div>
<div class="line">    else No Filter Provided</div>
<div class="line">        MDGen--&gt;&gt;MDGen: fit_markdown = &quot;&quot; (or None)</div>
<div class="line">    end</div>
<div class="line">    Note over MDGen: Generate citations if needed</div>
<div class="line">    MDGen--&gt;&gt;AWC: MarkdownGenerationResult (raw, fit, references)</div>
<div class="line">    AWC-&gt;&gt;Result: Package everything</div>
<div class="line">    AWC--&gt;&gt;User: Return CrawlResult</div>
</div><!-- fragment --><p><b>Code Glimpse:</b></p>
<p>Inside <code>crawl4ai/markdown_generation_strategy.py</code>, the <code>DefaultMarkdownGenerator</code>'s <code>generate_markdown</code> method has logic like this (simplified):</p>
<div class="fragment"><div class="line"><span class="comment"># Simplified from markdown_generation_strategy.py</span></div>
<div class="line"><span class="keyword">from</span> .models <span class="keyword">import</span> MarkdownGenerationResult</div>
<div class="line"><span class="keyword">from</span> .html2text <span class="keyword">import</span> CustomHTML2Text</div>
<div class="line"><span class="keyword">from</span> .content_filter_strategy <span class="keyword">import</span> RelevantContentFilter <span class="comment"># Import filter base class</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>DefaultMarkdownGenerator(MarkdownGenerationStrategy):</div>
<div class="line">    <span class="comment"># ... __init__ stores self.content_filter ...</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>generate_markdown(</div>
<div class="line">        self,</div>
<div class="line">        cleaned_html: str,</div>
<div class="line">        <span class="comment"># ... other params like base_url, options ...</span></div>
<div class="line">        content_filter: Optional[RelevantContentFilter] = <span class="keywordtype">None</span>,</div>
<div class="line">        **kwargs,</div>
<div class="line">    ) -&gt; MarkdownGenerationResult:</div>
<div class="line"> </div>
<div class="line">        h = CustomHTML2Text(...) <span class="comment"># Setup html2text converter</span></div>
<div class="line">        <span class="comment"># ... apply options ...</span></div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 1. Generate raw markdown from the full cleaned_html</span></div>
<div class="line">        raw_markdown = h.handle(cleaned_html)</div>
<div class="line">        <span class="comment"># ... post-process raw_markdown ...</span></div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 2. Convert links to citations (if enabled)</span></div>
<div class="line">        markdown_with_citations, references_markdown = self.convert_links_to_citations(...)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 3. Generate fit markdown IF a filter is available</span></div>
<div class="line">        fit_markdown = <span class="stringliteral">&quot;&quot;</span></div>
<div class="line">        filtered_html = <span class="stringliteral">&quot;&quot;</span></div>
<div class="line">        <span class="comment"># Use the filter passed directly, or the one stored during initialization</span></div>
<div class="line">        active_filter = content_filter <span class="keywordflow">or</span> self.content_filter</div>
<div class="line">        <span class="keywordflow">if</span> active_filter:</div>
<div class="line">            <span class="keywordflow">try</span>:</div>
<div class="line">                <span class="comment"># Call the filter&#39;s main method</span></div>
<div class="line">                filtered_html_fragments = active_filter.filter_content(cleaned_html)</div>
<div class="line">                <span class="comment"># Join fragments (assuming filter returns list of HTML strings)</span></div>
<div class="line">                filtered_html = <span class="stringliteral">&quot;\n&quot;</span>.join(filtered_html_fragments)</div>
<div class="line">                <span class="comment"># Convert ONLY the filtered HTML to markdown</span></div>
<div class="line">                fit_markdown = h.handle(filtered_html)</div>
<div class="line">            <span class="keywordflow">except</span> Exception <span class="keyword">as</span> e:</div>
<div class="line">                fit_markdown = f<span class="stringliteral">&quot;Error during filtering: {e}&quot;</span></div>
<div class="line">                <span class="comment"># Log error...</span></div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">return</span> MarkdownGenerationResult(</div>
<div class="line">            raw_markdown=raw_markdown,</div>
<div class="line">            markdown_with_citations=markdown_with_citations,</div>
<div class="line">            references_markdown=references_markdown,</div>
<div class="line">            fit_markdown=fit_markdown, <span class="comment"># Contains the filtered result</span></div>
<div class="line">            fit_html=filtered_html,     <span class="comment"># The HTML fragments kept by the filter</span></div>
<div class="line">        )</div>
</div><!-- fragment --><p>And inside <code>crawl4ai/content_filter_strategy.py</code>, you find the blueprint and implementations:</p>
<div class="fragment"><div class="line"><span class="comment"># Simplified from content_filter_strategy.py</span></div>
<div class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABC, abstractmethod</div>
<div class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List</div>
<div class="line"><span class="comment"># ... other imports like BeautifulSoup, BM25Okapi ...</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>RelevantContentFilter(ABC):</div>
<div class="line">    <span class="stringliteral">&quot;&quot;&quot;Abstract base class for content filtering strategies&quot;&quot;&quot;</span></div>
<div class="line">    <span class="keyword">def </span>__init__(self, user_query: str = <span class="keywordtype">None</span>, ...):</div>
<div class="line">        self.user_query = user_query</div>
<div class="line">        <span class="comment"># ... common setup ...</span></div>
<div class="line"> </div>
<div class="line">    <span class="preprocessor">@abstractmethod</span></div>
<div class="line">    <span class="keyword">def </span>filter_content(self, html: str) -&gt; List[str]:</div>
<div class="line">        <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="stringliteral">        Takes cleaned HTML, returns a list of HTML fragments</span></div>
<div class="line"><span class="stringliteral">        deemed relevant by the specific strategy.</span></div>
<div class="line"><span class="stringliteral">        &quot;&quot;&quot;</span></div>
<div class="line">        <span class="keywordflow">pass</span></div>
<div class="line">    <span class="comment"># ... common helper methods like extract_page_query, is_excluded ...</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>BM25ContentFilter(RelevantContentFilter):</div>
<div class="line">    <span class="keyword">def </span>__init__(self, user_query: str = <span class="keywordtype">None</span>, bm25_threshold: float = 1.0, ...):</div>
<div class="line">        super().__init__(user_query)</div>
<div class="line">        self.bm25_threshold = bm25_threshold</div>
<div class="line">        <span class="comment"># ... BM25 specific setup ...</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>filter_content(self, html: str) -&gt; List[str]:</div>
<div class="line">        <span class="comment"># 1. Parse HTML (e.g., with BeautifulSoup)</span></div>
<div class="line">        <span class="comment"># 2. Extract text chunks (candidates)</span></div>
<div class="line">        <span class="comment"># 3. Determine query (user_query or extracted)</span></div>
<div class="line">        <span class="comment"># 4. Tokenize query and chunks</span></div>
<div class="line">        <span class="comment"># 5. Calculate BM25 scores for chunks vs query</span></div>
<div class="line">        <span class="comment"># 6. Filter chunks based on score and threshold</span></div>
<div class="line">        <span class="comment"># 7. Return the HTML string of the selected chunks</span></div>
<div class="line">        <span class="comment"># ... implementation details ...</span></div>
<div class="line">        relevant_html_fragments = [<span class="stringliteral">&quot;&lt;p&gt;Relevant paragraph 1...&lt;/p&gt;&quot;</span>, <span class="stringliteral">&quot;&lt;h2&gt;Relevant Section&lt;/h2&gt;...&quot;</span>] <span class="comment"># Placeholder</span></div>
<div class="line">        <span class="keywordflow">return</span> relevant_html_fragments</div>
<div class="line"> </div>
<div class="line"><span class="comment"># ... Implementations for PruningContentFilter and LLMContentFilter ...</span></div>
</div><!-- fragment --><p>The key is that each filter implements the <code>filter_content</code> method, returning the list of HTML fragments it considers relevant. The <code>DefaultMarkdownGenerator</code> then uses these fragments to create the <code>fit_markdown</code>.</p>
<h2><a class="anchor" id="autotoc_md1433"></a>
Conclusion</h2>
<p>You've learned about <code>RelevantContentFilter</code>, Crawl4AI's "Relevance Sieve"!</p>
<ul>
<li>It addresses the problem that even cleaned HTML can contain noise relative to a specific goal.</li>
<li>It acts as a strategy to filter cleaned HTML, keeping only the relevant parts.</li>
<li>Different filter types exist: <code>BM25ContentFilter</code> (keywords), <code>PruningContentFilter</code> (structure), and <code>LLMContentFilter</code> (AI/semantic).</li>
<li>It's typically used <em>within</em> the <code>DefaultMarkdownGenerator</code> to produce a focused <code>fit_markdown</code> output in the <code>CrawlResult</code>, alongside the standard <code>raw_markdown</code>.</li>
<li>You configure it by passing the chosen filter instance to the <code>DefaultMarkdownGenerator</code> and then passing that generator to the <code>CrawlerRunConfig</code>.</li>
</ul>
<p>By using <code>RelevantContentFilter</code>, you can significantly improve the signal-to-noise ratio of the content you get from webpages, making downstream tasks like summarization or analysis more effective.</p>
<p>But what if just getting relevant <em>text</em> isn't enough? What if you need specific, <em>structured</em> data like product names, prices, and ratings from an e-commerce page, or names and affiliations from a list of conference speakers?</p>
<p><b>Next:</b> Let's explore how to extract structured data with <a class="el" href="../../d1/d07/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_206__extractionstrategy.html">Chapter 6: Getting Specific Data - ExtractionStrategy</a>.</p>
<hr  />
<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a> </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
