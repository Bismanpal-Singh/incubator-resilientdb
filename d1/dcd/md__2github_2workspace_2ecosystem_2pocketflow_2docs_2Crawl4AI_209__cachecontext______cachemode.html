#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
<!-- HTML header for doxygen 1.9.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ResilientDB: 09_cachecontext___cachemode</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen_html_style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../logo.png"/></td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('d1/dcd/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_209__cachecontext______cachemode.html','../../'); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">09_cachecontext___cachemode</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="autotoc_md1470"></a>
autotoc_md1470</h2>
<p>layout: default title: "CacheContext &amp; CacheMode" parent: "Crawl4AI" </p>
<h2><a class="anchor" id="autotoc_md1471"></a>
nav_order: 9</h2>
<h1><a class="anchor" id="autotoc_md1472"></a>
Chapter 9: Smart Fetching with Caching - CacheContext / CacheMode</h1>
<p>In the previous chapter, <a class="el" href="../../d3/da3/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_208__deepcrawlstrategy.html">Chapter 8: Exploring Websites - DeepCrawlStrategy</a>, we saw how Crawl4AI can explore websites by following links, potentially visiting many pages. During such explorations, or even when you run the same crawl multiple times, the crawler might try to fetch the exact same webpage again and again. This can be slow and might unnecessarily put a load on the website you're crawling. Wouldn't it be smarter to remember the result from the first time and just reuse it?</p>
<h2><a class="anchor" id="autotoc_md1473"></a>
What Problem Does Caching Solve?</h2>
<p>Imagine you need to download a large instruction manual (a webpage) from the internet.</p>
<ul>
<li><b>Without Caching:</b> Every single time you need the manual, you download the entire file again. This takes time and uses bandwidth every time.</li>
<li><b>With Caching:</b> The first time you download it, you save a copy on your computer (the "cache"). The next time you need it, you first check your local copy. If it's there, you use it instantly! You only download it again if you specifically want the absolute latest version or if your local copy is missing.</li>
</ul>
<p>Caching in Crawl4AI works the same way. It's a mechanism to <b>store the results</b> of crawling a webpage locally (in a database file). When asked to crawl a URL again, Crawl4AI can check its cache first. If a valid result is already stored, it can return that saved result almost instantly, saving time and resources.</p>
<h2><a class="anchor" id="autotoc_md1474"></a>
Introducing <code>CacheMode</code> and <code>CacheContext</code></h2>
<p>Crawl4AI uses two key concepts to manage this caching behavior:</p>
<ol type="1">
<li><b><code>CacheMode</code> (The Cache Policy):</b><ul>
<li>Think of this like setting the rules for how you interact with your saved instruction manuals.</li>
<li>It's an <b>instruction</b> you give the crawler for a specific run, telling it <em>how</em> to use the cache.</li>
<li><b>Analogy:</b> Should you <em>always</em> use your saved copy if you have one? (<code>ENABLED</code>) Should you <em>ignore</em> your saved copies and always download a fresh one? (<code>BYPASS</code>) Should you <em>never</em> save any copies? (<code>DISABLED</code>) Should you save new copies but never reuse old ones? (<code>WRITE_ONLY</code>)</li>
<li><code>CacheMode</code> lets you choose the caching behavior that best fits your needs for a particular task.</li>
</ul>
</li>
<li><b><code>CacheContext</code> (The Decision Maker):</b><ul>
<li>This is an internal helper that Crawl4AI uses <em>during</em> a crawl. You don't usually interact with it directly.</li>
<li>It looks at the <code>CacheMode</code> you provided (the policy) and the type of URL being processed.</li>
<li><b>Analogy:</b> Imagine a librarian who checks the library's borrowing rules (<code>CacheMode</code>) and the type of item you're requesting (e.g., a reference book that can't be checked out, like <code>raw:</code> HTML which isn't cached). Based on these, the librarian (<code>CacheContext</code>) decides if you can borrow an existing copy (read from cache) or if a new copy should be added to the library (write to cache).</li>
<li>It helps the main <code>AsyncWebCrawler</code> make the right decision about reading from or writing to the cache for each specific URL based on the active policy.</li>
</ul>
</li>
</ol>
<h2><a class="anchor" id="autotoc_md1475"></a>
Setting the Cache Policy: Using <code>CacheMode</code></h2>
<p>You control the caching behavior by setting the <code>cache_mode</code> parameter within the <code>CrawlerRunConfig</code> object that you pass to <code>crawler.arun()</code> or <code>crawler.arun_many()</code>.</p>
<p>Let's explore the most common <code>CacheMode</code> options:</p>
<p><b>1. <code>CacheMode.ENABLED</code> (The Default Behavior - If not specified)</b></p>
<ul>
<li><b>Policy:</b> "Use the cache if a valid result exists. If not, fetch the page, save the result to the cache, and then return it."</li>
<li>This is the standard, balanced approach. It saves time on repeated crawls but ensures you get the content eventually.</li>
<li><em>Note: In recent versions, the default if <code>cache_mode</code> is left completely unspecified might be <code>CacheMode.BYPASS</code>. Always check the documentation or explicitly set the mode for clarity.</em> For this tutorial, let's assume we explicitly set it.</li>
</ul>
<div class="fragment"><div class="line"><span class="comment"># chapter9_example_1.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    url = <span class="stringliteral">&quot;https://httpbin.org/html&quot;</span></div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        <span class="comment"># Explicitly set the mode to ENABLED</span></div>
<div class="line">        config_enabled = CrawlerRunConfig(cache_mode=CacheMode.ENABLED)</div>
<div class="line">        print(f<span class="stringliteral">&quot;Running with CacheMode: {config_enabled.cache_mode.name}&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># First run: Fetches, caches, and returns result</span></div>
<div class="line">        print(<span class="stringliteral">&quot;First run (ENABLED)...&quot;</span>)</div>
<div class="line">        result1 = await crawler.arun(url=url, config=config_enabled)</div>
<div class="line">        print(f<span class="stringliteral">&quot;Got result 1? {&#39;Yes&#39; if result1.success else &#39;No&#39;}&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># Second run: Finds result in cache and returns it instantly</span></div>
<div class="line">        print(<span class="stringliteral">&quot;Second run (ENABLED)...&quot;</span>)</div>
<div class="line">        result2 = await crawler.arun(url=url, config=config_enabled)</div>
<div class="line">        print(f<span class="stringliteral">&quot;Got result 2? {&#39;Yes&#39; if result2.success else &#39;No&#39;}&quot;</span>)</div>
<div class="line">        <span class="comment"># This second run should be much faster!</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
<div class="ttc" id="anamespacemain_html"><div class="ttname"><a href="../../d2/dc1/namespacemain.html">main</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/dba/main_8py_source.html#l00001">main.py:1</a></div></div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ul>
<li>We create a <code>CrawlerRunConfig</code> with <code>cache_mode=CacheMode.ENABLED</code>.</li>
<li>The first <code>arun</code> call fetches the page from the web and saves the result in the cache.</li>
<li>The second <code>arun</code> call (for the same URL and config affecting cache key) finds the saved result in the cache and returns it immediately, skipping the web fetch.</li>
</ul>
<p><b>2. <code>CacheMode.BYPASS</code></b></p>
<ul>
<li><b>Policy:</b> "Ignore any existing saved copy. Always fetch a fresh copy from the web. After fetching, save this new result to the cache (overwriting any old one)."</li>
<li>Useful when you <em>always</em> need the absolute latest version of the page, but you still want to update the cache for potential future use with <code>CacheMode.ENABLED</code>.</li>
</ul>
<div class="fragment"><div class="line"><span class="comment"># chapter9_example_2.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode</div>
<div class="line"><span class="keyword">import</span> time</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    url = <span class="stringliteral">&quot;https://httpbin.org/html&quot;</span></div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        <span class="comment"># Set the mode to BYPASS</span></div>
<div class="line">        config_bypass = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)</div>
<div class="line">        print(f<span class="stringliteral">&quot;Running with CacheMode: {config_bypass.cache_mode.name}&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># First run: Fetches, caches, and returns result</span></div>
<div class="line">        print(<span class="stringliteral">&quot;First run (BYPASS)...&quot;</span>)</div>
<div class="line">        start_time = time.perf_counter()</div>
<div class="line">        result1 = await crawler.arun(url=url, config=config_bypass)</div>
<div class="line">        duration1 = time.perf_counter() - start_time</div>
<div class="line">        print(f<span class="stringliteral">&quot;Got result 1? {&#39;Yes&#39; if result1.success else &#39;No&#39;} (took {duration1:.2f}s)&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># Second run: Ignores cache, fetches again, updates cache, returns result</span></div>
<div class="line">        print(<span class="stringliteral">&quot;Second run (BYPASS)...&quot;</span>)</div>
<div class="line">        start_time = time.perf_counter()</div>
<div class="line">        result2 = await crawler.arun(url=url, config=config_bypass)</div>
<div class="line">        duration2 = time.perf_counter() - start_time</div>
<div class="line">        print(f<span class="stringliteral">&quot;Got result 2? {&#39;Yes&#39; if result2.success else &#39;No&#39;} (took {duration2:.2f}s)&quot;</span>)</div>
<div class="line">        <span class="comment"># Both runs should take a similar amount of time (fetching time)</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ul>
<li>We set <code>cache_mode=CacheMode.BYPASS</code>.</li>
<li>Both the first and second <code>arun</code> calls will fetch the page directly from the web, ignoring any previously cached result. They will still write the newly fetched result to the cache. Notice both runs take roughly the same amount of time (network fetch time).</li>
</ul>
<p><b>3. <code>CacheMode.DISABLED</code></b></p>
<ul>
<li><b>Policy:</b> "Completely ignore the cache. Never read from it, never write to it."</li>
<li>Useful when you don't want Crawl4AI to interact with the cache files at all, perhaps for debugging or if you have storage constraints.</li>
</ul>
<div class="fragment"><div class="line"><span class="comment"># chapter9_example_3.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode</div>
<div class="line"><span class="keyword">import</span> time</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    url = <span class="stringliteral">&quot;https://httpbin.org/html&quot;</span></div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        <span class="comment"># Set the mode to DISABLED</span></div>
<div class="line">        config_disabled = CrawlerRunConfig(cache_mode=CacheMode.DISABLED)</div>
<div class="line">        print(f<span class="stringliteral">&quot;Running with CacheMode: {config_disabled.cache_mode.name}&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># First run: Fetches, returns result (does NOT cache)</span></div>
<div class="line">        print(<span class="stringliteral">&quot;First run (DISABLED)...&quot;</span>)</div>
<div class="line">        start_time = time.perf_counter()</div>
<div class="line">        result1 = await crawler.arun(url=url, config=config_disabled)</div>
<div class="line">        duration1 = time.perf_counter() - start_time</div>
<div class="line">        print(f<span class="stringliteral">&quot;Got result 1? {&#39;Yes&#39; if result1.success else &#39;No&#39;} (took {duration1:.2f}s)&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># Second run: Fetches again, returns result (does NOT cache)</span></div>
<div class="line">        print(<span class="stringliteral">&quot;Second run (DISABLED)...&quot;</span>)</div>
<div class="line">        start_time = time.perf_counter()</div>
<div class="line">        result2 = await crawler.arun(url=url, config=config_disabled)</div>
<div class="line">        duration2 = time.perf_counter() - start_time</div>
<div class="line">        print(f<span class="stringliteral">&quot;Got result 2? {&#39;Yes&#39; if result2.success else &#39;No&#39;} (took {duration2:.2f}s)&quot;</span>)</div>
<div class="line">        <span class="comment"># Both runs fetch fresh, and nothing is ever saved to the cache.</span></div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ul>
<li>We set <code>cache_mode=CacheMode.DISABLED</code>.</li>
<li>Both <code>arun</code> calls fetch fresh content from the web. Crucially, neither run reads from nor writes to the cache database.</li>
</ul>
<p><b>Other Modes (<code>READ_ONLY</code>, <code>WRITE_ONLY</code>):</b></p>
<ul>
<li><code>CacheMode.READ_ONLY</code>: Only uses existing cached results. If a result isn't in the cache, it will fail or return an empty result rather than fetching it. Never saves anything new.</li>
<li><code>CacheMode.WRITE_ONLY</code>: Never reads from the cache (always fetches fresh). It <em>only</em> writes the newly fetched result to the cache.</li>
</ul>
<h2><a class="anchor" id="autotoc_md1476"></a>
How Caching Works Internally</h2>
<p>When you call <code>crawler.arun(url="...", config=...)</code>:</p>
<ol type="1">
<li><b>Create Context:</b> The <code>AsyncWebCrawler</code> creates a <code>CacheContext</code> instance using the <code>url</code> and the <code>config.cache_mode</code>.</li>
<li><b>Check Read:</b> It asks the <code>CacheContext</code>, "Should I read from the cache?" (<code>cache_context.should_read()</code>).</li>
<li><b>Try Reading:</b> If <code>should_read()</code> is <code>True</code>, it asks the database manager (<a href="../../async_database.py"><code>AsyncDatabaseManager</code></a>) to look for a cached result for the <code>url</code>.</li>
<li><b>Cache Hit?</b><ul>
<li>If a valid cached result is found: The <code>AsyncWebCrawler</code> returns this cached <code>CrawlResult</code> immediately. Done!</li>
<li>If no cached result is found (or if <code>should_read()</code> was <code>False</code>): Proceed to fetching.</li>
</ul>
</li>
<li><b>Fetch:</b> The <code>AsyncWebCrawler</code> calls the appropriate <a class="el" href="../../dc/d53/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_201__asynccrawlerstrategy.html">AsyncCrawlerStrategy</a> to fetch the content from the web.</li>
<li><b>Process:</b> It processes the fetched HTML (scraping, filtering, extracting) to create a new <code>CrawlResult</code>.</li>
<li><b>Check Write:</b> It asks the <code>CacheContext</code>, "Should I write this result to the cache?" (<code>cache_context.should_write()</code>).</li>
<li><b>Write Cache:</b> If <code>should_write()</code> is <code>True</code>, it tells the database manager to save the new <code>CrawlResult</code> into the cache database.</li>
<li><b>Return:</b> The <code>AsyncWebCrawler</code> returns the newly created <code>CrawlResult</code>.</li>
</ol>
<div class="fragment"><div class="line">sequenceDiagram</div>
<div class="line">    participant User</div>
<div class="line">    participant AWC as AsyncWebCrawler</div>
<div class="line">    participant Ctx as CacheContext</div>
<div class="line">    participant DB as DatabaseManager</div>
<div class="line">    participant Fetcher as AsyncCrawlerStrategy</div>
<div class="line"> </div>
<div class="line">    User-&gt;&gt;AWC: arun(url, config)</div>
<div class="line">    AWC-&gt;&gt;Ctx: Create CacheContext(url, config.cache_mode)</div>
<div class="line">    AWC-&gt;&gt;Ctx: should_read()?</div>
<div class="line">    alt Cache Read Allowed</div>
<div class="line">        Ctx--&gt;&gt;AWC: Yes</div>
<div class="line">        AWC-&gt;&gt;DB: aget_cached_url(url)</div>
<div class="line">        DB--&gt;&gt;AWC: Cached Result (or None)</div>
<div class="line">        alt Cache Hit &amp; Valid</div>
<div class="line">            AWC--&gt;&gt;User: Return Cached CrawlResult</div>
<div class="line">        else Cache Miss or Invalid</div>
<div class="line">            AWC-&gt;&gt;AWC: Proceed to Fetch</div>
<div class="line">        end</div>
<div class="line">    else Cache Read Not Allowed</div>
<div class="line">        Ctx--&gt;&gt;AWC: No</div>
<div class="line">        AWC-&gt;&gt;AWC: Proceed to Fetch</div>
<div class="line">    end</div>
<div class="line"> </div>
<div class="line">    Note over AWC: Fetching Required</div>
<div class="line">    AWC-&gt;&gt;Fetcher: crawl(url, config)</div>
<div class="line">    Fetcher--&gt;&gt;AWC: Raw Response</div>
<div class="line">    AWC-&gt;&gt;AWC: Process HTML -&gt; New CrawlResult</div>
<div class="line">    AWC-&gt;&gt;Ctx: should_write()?</div>
<div class="line">    alt Cache Write Allowed</div>
<div class="line">        Ctx--&gt;&gt;AWC: Yes</div>
<div class="line">        AWC-&gt;&gt;DB: acache_url(New CrawlResult)</div>
<div class="line">        DB--&gt;&gt;AWC: OK</div>
<div class="line">    else Cache Write Not Allowed</div>
<div class="line">        Ctx--&gt;&gt;AWC: No</div>
<div class="line">    end</div>
<div class="line">    AWC--&gt;&gt;User: Return New CrawlResult</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md1477"></a>
Code Glimpse</h2>
<p>Let's look at simplified code snippets.</p>
<p><b>Inside <code>async_webcrawler.py</code> (where <code>arun</code> uses caching):</b></p>
<div class="fragment"><div class="line"><span class="comment"># Simplified from crawl4ai/async_webcrawler.py</span></div>
<div class="line"><span class="keyword">from</span> .cache_context <span class="keyword">import</span> CacheContext, CacheMode</div>
<div class="line"><span class="keyword">from</span> .async_database <span class="keyword">import</span> async_db_manager</div>
<div class="line"><span class="keyword">from</span> .models <span class="keyword">import</span> CrawlResult</div>
<div class="line"><span class="comment"># ... other imports</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>AsyncWebCrawler:</div>
<div class="line">    <span class="comment"># ... (init, other methods) ...</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">async def </span>arun(self, url: str, config: CrawlerRunConfig = <span class="keywordtype">None</span>) -&gt; CrawlResult:</div>
<div class="line">        <span class="comment"># ... (ensure config exists, set defaults) ...</span></div>
<div class="line">        <span class="keywordflow">if</span> config.cache_mode <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line">            config.cache_mode = CacheMode.ENABLED <span class="comment"># Example default</span></div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 1. Create CacheContext</span></div>
<div class="line">        cache_context = CacheContext(url, config.cache_mode)</div>
<div class="line"> </div>
<div class="line">        cached_result = <span class="keywordtype">None</span></div>
<div class="line">        <span class="comment"># 2. Check if cache read is allowed</span></div>
<div class="line">        <span class="keywordflow">if</span> cache_context.should_read():</div>
<div class="line">            <span class="comment"># 3. Try reading from database</span></div>
<div class="line">            cached_result = await async_db_manager.aget_cached_url(url)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 4. If cache hit and valid, return it</span></div>
<div class="line">        <span class="keywordflow">if</span> cached_result <span class="keywordflow">and</span> self._is_cache_valid(cached_result, config):</div>
<div class="line">            self.logger.info(<span class="stringliteral">&quot;Cache hit for: %s&quot;</span>, url) <span class="comment"># Example log</span></div>
<div class="line">            <span class="keywordflow">return</span> cached_result <span class="comment"># Return early</span></div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 5. Fetch fresh content (if no cache hit or read disabled)</span></div>
<div class="line">        async_response = await self.crawler_strategy.crawl(url, config=config)</div>
<div class="line">        html = async_response.html <span class="comment"># ... and other data ...</span></div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 6. Process the HTML to get a new CrawlResult</span></div>
<div class="line">        crawl_result = await self.aprocess_html(</div>
<div class="line">            url=url, html=html, config=config, <span class="comment"># ... other params ...</span></div>
<div class="line">        )</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 7. Check if cache write is allowed</span></div>
<div class="line">        <span class="keywordflow">if</span> cache_context.should_write():</div>
<div class="line">            <span class="comment"># 8. Write the new result to the database</span></div>
<div class="line">            await async_db_manager.acache_url(crawl_result)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 9. Return the new result</span></div>
<div class="line">        <span class="keywordflow">return</span> crawl_result</div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>_is_cache_valid(self, cached_result: CrawlResult, config: CrawlerRunConfig) -&gt; bool:</div>
<div class="line">        <span class="comment"># Internal logic to check if cached result meets current needs</span></div>
<div class="line">        <span class="comment"># (e.g., was screenshot requested now but not cached?)</span></div>
<div class="line">        <span class="keywordflow">if</span> config.screenshot <span class="keywordflow">and</span> <span class="keywordflow">not</span> cached_result.screenshot: <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line">        <span class="keywordflow">if</span> config.pdf <span class="keywordflow">and</span> <span class="keywordflow">not</span> cached_result.pdf: <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line">        <span class="comment"># ... other checks ...</span></div>
<div class="line">        <span class="keywordflow">return</span> <span class="keyword">True</span></div>
</div><!-- fragment --><p><b>Inside <code>cache_context.py</code> (defining the concepts):</b></p>
<div class="fragment"><div class="line"><span class="comment"># Simplified from crawl4ai/cache_context.py</span></div>
<div class="line"><span class="keyword">from</span> enum <span class="keyword">import</span> Enum</div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>CacheMode(Enum):</div>
<div class="line">    <span class="stringliteral">&quot;&quot;&quot;Defines the caching behavior for web crawling operations.&quot;&quot;&quot;</span></div>
<div class="line">    ENABLED = <span class="stringliteral">&quot;enabled&quot;</span>     <span class="comment"># Read and Write</span></div>
<div class="line">    DISABLED = <span class="stringliteral">&quot;disabled&quot;</span>    <span class="comment"># No Read, No Write</span></div>
<div class="line">    READ_ONLY = <span class="stringliteral">&quot;read_only&quot;</span>  <span class="comment"># Read Only, No Write</span></div>
<div class="line">    WRITE_ONLY = <span class="stringliteral">&quot;write_only&quot;</span> <span class="comment"># Write Only, No Read</span></div>
<div class="line">    BYPASS = <span class="stringliteral">&quot;bypass&quot;</span>      <span class="comment"># No Read, Write Only (similar to WRITE_ONLY but explicit intention)</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>CacheContext:</div>
<div class="line">    <span class="stringliteral">&quot;&quot;&quot;Encapsulates cache-related decisions and URL handling.&quot;&quot;&quot;</span></div>
<div class="line">    <span class="keyword">def </span>__init__(self, url: str, cache_mode: CacheMode, always_bypass: bool = <span class="keyword">False</span>):</div>
<div class="line">        self.url = url</div>
<div class="line">        self.cache_mode = cache_mode</div>
<div class="line">        self.always_bypass = always_bypass <span class="comment"># Usually False</span></div>
<div class="line">        <span class="comment"># Determine if URL type is cacheable (e.g., not &#39;raw:&#39;)</span></div>
<div class="line">        self.is_cacheable = url.startswith((<span class="stringliteral">&quot;http://&quot;</span>, <span class="stringliteral">&quot;https://&quot;</span>, <span class="stringliteral">&quot;file://&quot;</span>))</div>
<div class="line">        <span class="comment"># ... other URL type checks ...</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>should_read(self) -&gt; bool:</div>
<div class="line">        <span class="stringliteral">&quot;&quot;&quot;Determines if cache should be read based on context.&quot;&quot;&quot;</span></div>
<div class="line">        <span class="keywordflow">if</span> self.always_bypass <span class="keywordflow">or</span> <span class="keywordflow">not</span> self.is_cacheable:</div>
<div class="line">            <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line">        <span class="comment"># Allow read if mode is ENABLED or READ_ONLY</span></div>
<div class="line">        <span class="keywordflow">return</span> self.cache_mode <span class="keywordflow">in</span> [CacheMode.ENABLED, CacheMode.READ_ONLY]</div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>should_write(self) -&gt; bool:</div>
<div class="line">        <span class="stringliteral">&quot;&quot;&quot;Determines if cache should be written based on context.&quot;&quot;&quot;</span></div>
<div class="line">        <span class="keywordflow">if</span> self.always_bypass <span class="keywordflow">or</span> <span class="keywordflow">not</span> self.is_cacheable:</div>
<div class="line">            <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line">        <span class="comment"># Allow write if mode is ENABLED, WRITE_ONLY, or BYPASS</span></div>
<div class="line">        <span class="keywordflow">return</span> self.cache_mode <span class="keywordflow">in</span> [CacheMode.ENABLED, CacheMode.WRITE_ONLY, CacheMode.BYPASS]</div>
<div class="line"> </div>
<div class="line">    <span class="preprocessor">@property</span></div>
<div class="line">    <span class="keyword">def </span>display_url(self) -&gt; str:</div>
<div class="line">        <span class="stringliteral">&quot;&quot;&quot;Returns the URL in display format.&quot;&quot;&quot;</span></div>
<div class="line">        <span class="keywordflow">return</span> self.url <span class="keywordflow">if</span> <span class="keywordflow">not</span> self.url.startswith(<span class="stringliteral">&quot;raw:&quot;</span>) <span class="keywordflow">else</span> <span class="stringliteral">&quot;Raw HTML&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="comment"># Helper for backward compatibility (may be removed later)</span></div>
<div class="line"><span class="keyword">def </span>_legacy_to_cache_mode(...) -&gt; CacheMode:</div>
<div class="line">    <span class="comment"># ... logic to convert old boolean flags ...</span></div>
<div class="line">    <span class="keywordflow">pass</span></div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md1478"></a>
Conclusion</h2>
<p>You've learned how Crawl4AI uses caching to avoid redundant work and speed up repeated crawls!</p>
<ul>
<li><b>Caching</b> stores results locally to reuse them later.</li>
<li><b><code>CacheMode</code></b> is the policy you set in <code>CrawlerRunConfig</code> to control <em>how</em> the cache is used (<code>ENABLED</code>, <code>BYPASS</code>, <code>DISABLED</code>, etc.).</li>
<li><b><code>CacheContext</code></b> is an internal helper that makes decisions based on the <code>CacheMode</code> and URL type.</li>
<li>Using the cache effectively (especially <code>CacheMode.ENABLED</code>) can significantly speed up your crawling tasks, particularly during development or when dealing with many URLs, including deep crawls.</li>
</ul>
<p>We've seen how Crawl4AI can crawl single pages, lists of pages (<code>arun_many</code>), and even explore websites (<code>DeepCrawlStrategy</code>). But how does <code>arun_many</code> or a deep crawl manage running potentially hundreds or thousands of individual crawl tasks efficiently without overwhelming your system or the target website?</p>
<p><b>Next:</b> Let's explore the component responsible for managing concurrent tasks: <a class="el" href="../../d6/d6d/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_210__basedispatcher.html">Chapter 10: Orchestrating the Crawl - BaseDispatcher</a>.</p>
<hr  />
<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a> </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
