#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
<!-- HTML header for doxygen 1.9.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ResilientDB: 08_teleprompter___optimizer</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen_html_style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../logo.png"/></td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dc/d0a/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2DSPy_208__teleprompter______optimizer.html','../../'); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">08_teleprompter___optimizer</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="autotoc_md1664"></a>
autotoc_md1664</h2>
<p>layout: default title: "Teleprompter &amp; Optimizer" parent: "DSPy" </p>
<h2><a class="anchor" id="autotoc_md1665"></a>
nav_order: 8</h2>
<h1><a class="anchor" id="autotoc_md1666"></a>
Chapter 8: Teleprompter / Optimizer - Your Program's Coach</h1>
<p>Welcome to Chapter 8! In <a class="el" href="../../d5/daa/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2DSPy_207__evaluate.html">Chapter 7: Evaluate</a>, we learned how to grade our DSPy programs using metrics and datasets to see how well they perform. That's great for knowing our score, but what if the score isn't high enough?</p>
<p>Think about building our <code>BasicQA</code> program from the last chapter. Maybe we tried running it and found it only got 75% accuracy. How do we improve it?</p>
<p>Traditionally, we might start <b>manually tweaking prompts</b>:</p><ul>
<li>"Maybe I should rephrase the instructions?"</li>
<li>"Should I add some examples (few-shot demonstrations)?"</li>
<li>"Which examples work best?"</li>
</ul>
<p>This manual process, often called "prompt engineering," can be slow, tedious, and requires a lot of guesswork. Wouldn't it be amazing if DSPy could <b>automatically figure out the best prompts and examples</b> for us?</p>
<p>That's exactly what <b>Teleprompters</b> (also called Optimizers) do! They are DSPy's built-in automated prompt engineers and program tuners.</p>
<p>Think of a Teleprompter as a <b>coach</b> for your DSPy program (the 'student'):</p><ul>
<li>The coach observes how the student performs on practice drills (a dataset).</li>
<li>It uses feedback (a metric) to figure out weaknesses.</li>
<li>It suggests new strategies (better instructions, better examples) to improve performance.</li>
<li>It repeats this until the student performs much better!</li>
</ul>
<p>In this chapter, we'll learn:</p>
<ul>
<li>What a Teleprompter is and the problem it solves.</li>
<li>The key ingredients needed to use a Teleprompter.</li>
<li>How to use a simple Teleprompter (<code>BootstrapFewShot</code>) to automatically find good few-shot examples.</li>
<li>The basic idea behind how Teleprompters optimize programs.</li>
</ul>
<p>Let's automate the improvement process!</p>
<h2><a class="anchor" id="autotoc_md1667"></a>
What is a Teleprompter / Optimizer?</h2>
<p>A <code>Teleprompter</code> in DSPy is an algorithm that takes your DSPy <a class="el" href="../../d8/d9f/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2DSPy_201__module______program.html">Program</a> (the 'student') and automatically tunes its internal parameters to maximize performance on a given task. These parameters are most often:</p>
<ol type="1">
<li><b>Instructions:</b> The natural language guidance given to the Language Models (<a class="el" href="../../d9/db7/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2DSPy_205__lm____language__model__client__.html">LM</a>) within your program's modules (like <code>dspy.Predict</code>).</li>
<li><b>Few-Shot Examples (Demos):</b> The <code>dspy.Example</code> objects provided in prompts to show the LM how to perform the task.</li>
</ol>
<p>Some advanced Teleprompters can even fine-tune the weights of the LM itself!</p>
<p>To work its magic, a Teleprompter needs three things (sound familiar? They're similar to evaluation!):</p>
<ol type="1">
<li><b>The Student Program:</b> The DSPy program you want to improve.</li>
<li><b>A Training Dataset (<code>trainset</code>):</b> A list of <code>dspy.Example</code> objects (<a class="el" href="../../dc/db9/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2DSPy_203__example.html">Chapter 3: Example</a>) representing the task. The Teleprompter will use this data to practice and learn.</li>
<li><b>A Metric Function (<code>metric</code>):</b> The same kind of function we used in <a class="el" href="../../d5/daa/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2DSPy_207__evaluate.html">Chapter 7: Evaluate</a>. It tells the Teleprompter how well the student program is doing on each example in the <code>trainset</code>.</li>
</ol>
<p>The Teleprompter uses the <code>metric</code> to guide its search for better instructions or demos, trying different combinations and keeping the ones that yield the highest score on the <code>trainset</code>. The output is an <b>optimized version of your student program</b>.</p>
<h2><a class="anchor" id="autotoc_md1668"></a>
Use Case: Automatically Finding Good Few-Shot Examples with <code>BootstrapFewShot</code></h2>
<p>Let's revisit our <code>BasicQA</code> program and the evaluation setup from Chapter 7.</p>
<div class="fragment"><div class="line"><span class="keyword">import</span> dspy</div>
<div class="line"><span class="keyword">from</span> dspy.evaluate <span class="keyword">import</span> Evaluate</div>
<div class="line"><span class="comment"># Assume LM is configured (e.g., dspy.settings.configure(lm=...))</span></div>
<div class="line"> </div>
<div class="line"><span class="comment"># Our simple program</span></div>
<div class="line"><span class="keyword">class </span>BasicQA(dspy.Module):</div>
<div class="line">    <span class="keyword">def </span>__init__(self):</div>
<div class="line">        super().__init__()</div>
<div class="line">        self.predictor = dspy.Predict(<span class="stringliteral">&#39;question -&gt; answer&#39;</span>)</div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>forward(self, question):</div>
<div class="line">        <span class="keywordflow">return</span> self.predictor(question=question)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Our metric from Chapter 7</span></div>
<div class="line"><span class="keyword">def </span>simple_exact_match_metric(gold, prediction, trace=None):</div>
<div class="line">    <span class="keywordflow">return</span> prediction.answer.lower() == gold.answer.lower()</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Our dataset from Chapter 7 (let&#39;s use it as a trainset now)</span></div>
<div class="line">dev_example1 = dspy.Example(question=<span class="stringliteral">&quot;What color is the sky?&quot;</span>, answer=<span class="stringliteral">&quot;blue&quot;</span>)</div>
<div class="line">dev_example2 = dspy.Example(question=<span class="stringliteral">&quot;What is 2 + 2?&quot;</span>, answer=<span class="stringliteral">&quot;4&quot;</span>)</div>
<div class="line">dev_example3 = dspy.Example(question=<span class="stringliteral">&quot;What is the capital of France?&quot;</span>, answer=<span class="stringliteral">&quot;Paris&quot;</span>)</div>
<div class="line"><span class="comment"># Example our program might struggle with initially</span></div>
<div class="line">dev_example_hard = dspy.Example(question=<span class="stringliteral">&quot;Who painted the Mona Lisa?&quot;</span>, answer=<span class="stringliteral">&quot;Leonardo da Vinci&quot;</span>)</div>
<div class="line"> </div>
<div class="line">trainset = [dev_example1, dev_example2, dev_example3, dev_example_hard]</div>
<div class="line">trainset = [d.with_inputs(<span class="stringliteral">&#39;question&#39;</span>) <span class="keywordflow">for</span> d <span class="keywordflow">in</span> trainset]</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Let&#39;s evaluate the initial program (likely imperfect)</span></div>
<div class="line">initial_program = BasicQA()</div>
<div class="line">evaluator = Evaluate(devset=trainset, metric=simple_exact_match_metric, display_progress=<span class="keyword">False</span>)</div>
<div class="line">initial_score = evaluator(initial_program)</div>
<div class="line">print(f<span class="stringliteral">&quot;Initial Score (on trainset): {initial_score}%&quot;</span>)</div>
<div class="line"><span class="comment"># Might output: Initial Score (on trainset): 75.0% (assuming it fails the last one)</span></div>
</div><!-- fragment --><p>Our initial program gets 75%. We could try adding few-shot examples manually, but which ones? And how many?</p>
<p>Let's use <code>dspy.teleprompt.BootstrapFewShot</code>. This Teleprompter automatically creates and selects few-shot demonstrations for the predictors in your program.</p>
<p><b>1. Import the Teleprompter:</b></p>
<div class="fragment"><div class="line"><span class="keyword">from</span> dspy.teleprompt <span class="keyword">import</span> BootstrapFewShot</div>
</div><!-- fragment --><p><b>2. Instantiate the Teleprompter:</b> We need to give it the <code>metric</code> function it should use to judge success. We can also specify how many candidate demos (<code>max_bootstrapped_demos</code>) it should try to find for each predictor.</p>
<div class="fragment"><div class="line"><span class="comment"># Configure the BootstrapFewShot optimizer</span></div>
<div class="line"><span class="comment"># It will use the metric to find successful demonstrations</span></div>
<div class="line"><span class="comment"># max_bootstrapped_demos=4 means it will try to find up to 4 good examples for EACH predictor</span></div>
<div class="line">config = dict(max_bootstrapped_demos=4, metric=simple_exact_match_metric)</div>
<div class="line">teleprompter = BootstrapFewShot(**config)</div>
</div><!-- fragment --><p><b>3. Compile the Program:</b> This is the main step. We call the Teleprompter's <code>compile</code> method, giving it our initial <code>student</code> program and the <code>trainset</code>. It returns a <em>new</em>, optimized program.</p>
<div class="fragment"><div class="line"><span class="comment"># Compile the program!</span></div>
<div class="line"><span class="comment"># This runs the optimization process using the trainset.</span></div>
<div class="line"><span class="comment"># It uses a &#39;teacher&#39; model (often the student itself or a copy)</span></div>
<div class="line"><span class="comment"># to generate traces, finds successful ones via the metric,</span></div>
<div class="line"><span class="comment"># and adds them as demos to the student&#39;s predictors.</span></div>
<div class="line">compiled_program = teleprompter.compile(student=initial_program, trainset=trainset)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># The &#39;compiled_program&#39; is a new instance of BasicQA,</span></div>
<div class="line"><span class="comment"># but its internal predictor now has few-shot examples added!</span></div>
</div><!-- fragment --><p><b>What just happened?</b></p>
<p>Behind the scenes, <code>BootstrapFewShot</code> (conceptually):</p><ul>
<li>Used a "teacher" program (often a copy of the student or another specified LM configuration) to run each example in the <code>trainset</code>.</li>
<li>For each example, it checked if the teacher's output was correct using our <code>simple_exact_match_metric</code>.</li>
<li>If an example was processed correctly, the Teleprompter saved the input/output pair as a potential "demonstration" (a good example).</li>
<li>It collected these successful demonstrations.</li>
<li>It assigned a selection of these good demonstrations (<code>max_bootstrapped_demos</code>) to the <code>demos</code> attribute of the corresponding predictor inside our <code>compiled_program</code>.</li>
</ul>
<p><b>4. Evaluate the Compiled Program:</b> Now, let's see if the optimized program performs better on the same <code>trainset</code>.</p>
<div class="fragment"><div class="line"><span class="comment"># Evaluate the compiled program</span></div>
<div class="line">compiled_score = evaluator(compiled_program)</div>
<div class="line">print(f<span class="stringliteral">&quot;Compiled Score (on trainset): {compiled_score}%&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># If the optimization worked, the score should be higher!</span></div>
<div class="line"><span class="comment"># Might output: Compiled Score (on trainset): 100.0%</span></div>
</div><!-- fragment --><p>If <code>BootstrapFewShot</code> found good examples (like the "Mona Lisa" one after the teacher model successfully answered it), the <code>compiled_program</code> now has these examples embedded in its prompts, helping the LM perform better on similar questions. We automated the process of finding effective few-shot examples!</p>
<h2><a class="anchor" id="autotoc_md1669"></a>
How Optimization Works (Conceptual)</h2>
<p>Different Teleprompters use different strategies, but the core idea is usually:</p>
<ol type="1">
<li><b>Goal:</b> Find program parameters (instructions, demos) that maximize the <code>metric</code> score on the <code>trainset</code>.</li>
<li><b>Search Space:</b> The "space" of all possible instructions or combinations of demos.</li>
<li><b>Search Strategy:</b> How the Teleprompter explores this space.<ul>
<li><code>BootstrapFewShot</code>: Generates candidate demos based on successful teacher executions.</li>
<li>Other optimizers (like <code>COPRO</code> or <code>MIPROv2</code> mentioned in the code snippets) might use an LM to <em>propose</em> new instructions, evaluate them, and iterate. Some use sophisticated search algorithms like Bayesian Optimization or random search.</li>
</ul>
</li>
<li><b>Evaluation:</b> Use the <code>metric</code> and <code>trainset</code> to score each candidate configuration (e.g., a program with specific demos or instructions).</li>
<li><b>Selection:</b> Keep the configuration that resulted in the best score.</li>
</ol>
<p><b>Analogy Revisited:</b></p>
<ul>
<li><b>Coach:</b> The Teleprompter algorithm (<code>BootstrapFewShot</code>).</li>
<li><b>Student:</b> Your DSPy <code>Program</code> (<code>initial_program</code>).</li>
<li><b>Practice Drills:</b> The <code>trainset</code>.</li>
<li><b>Scoring:</b> The <code>metric</code> function (<code>simple_exact_match_metric</code>).</li>
<li><b>Trying Techniques:</b> Generating/selecting different demos or instructions.</li>
<li><b>Adopting Best Techniques:</b> Creating the <code>compiled_program</code> with the highest-scoring demos/instructions found.</li>
</ul>
<h2><a class="anchor" id="autotoc_md1670"></a>
How It Works Under the Hood (<code>BootstrapFewShot</code> Peek)</h2>
<p>Let's briefly look at the internal flow for <code>BootstrapFewShot.compile()</code>:</p>
<ol type="1">
<li><b>Prepare Teacher:</b> It sets up a 'teacher' program. This is often a copy of the student program, sometimes configured with specific settings (like a higher temperature for more exploration) or potentially using labeled examples if provided (<code>LabeledFewShot</code> within <code>BootstrapFewShot</code>).</li>
<li><b>Iterate Trainset:</b> It goes through each <code>example</code> in the <code>trainset</code>.</li>
<li><b>Teacher Execution:</b> For each <code>example</code>, it runs the <code>teacher</code> program (<code>teacher(**example.inputs())</code>). This happens within a <code>dspy.settings.context</code> block to capture the execution <code>trace</code>.</li>
<li><b>Metric Check:</b> It uses the provided <code>metric</code> to compare the <code>teacher</code>'s prediction against the <code>example</code>'s gold label (<code>metric(example, prediction, trace)</code>).</li>
<li><b>Collect Demos:</b> If the <code>metric</code> returns success (e.g., <code>True</code> or a score above a threshold), the Teleprompter extracts the input/output steps from the execution <code>trace</code>. Each successful trace step can become a candidate <code>dspy.Example</code> demonstration.</li>
<li><b>Assign Demos:</b> After iterating through the <code>trainset</code>, it takes the collected successful demonstrations (up to <code>max_bootstrapped_demos</code>) and assigns them to the <code>demos</code> attribute of the corresponding predictors in the <code>student</code> program instance.</li>
<li><b>Return Compiled Student:</b> It returns the modified <code>student</code> program, which now contains the bootstrapped few-shot examples.</li>
</ol>
<div class="fragment"><div class="line">sequenceDiagram</div>
<div class="line">    participant User</div>
<div class="line">    participant Teleprompter as BootstrapFewShot</div>
<div class="line">    participant StudentProgram as Student Program</div>
<div class="line">    participant TeacherProgram as Teacher Program</div>
<div class="line">    participant LM as Language Model</div>
<div class="line">    participant Metric as Metric Function</div>
<div class="line">    participant CompiledProgram as Compiled Program (Student with Demos)</div>
<div class="line"> </div>
<div class="line">    User-&gt;&gt;Teleprompter: compile(student=StudentProgram, trainset=...)</div>
<div class="line">    Teleprompter-&gt;&gt;TeacherProgram: Set up (copy of student, potentially modified)</div>
<div class="line">    loop For each example in trainset</div>
<div class="line">        Teleprompter-&gt;&gt;TeacherProgram: Run example.inputs()</div>
<div class="line">        TeacherProgram-&gt;&gt;LM: Make calls (via Predictors)</div>
<div class="line">        LM--&gt;&gt;TeacherProgram: Return predictions</div>
<div class="line">        TeacherProgram--&gt;&gt;Teleprompter: Return final prediction &amp; trace</div>
<div class="line">        Teleprompter-&gt;&gt;Metric: Evaluate(example, prediction, trace)</div>
<div class="line">        Metric--&gt;&gt;Teleprompter: Return score (success/fail)</div>
<div class="line">        alt Metric returns success</div>
<div class="line">            Teleprompter-&gt;&gt;Teleprompter: Extract demo from trace</div>
<div class="line">        end</div>
<div class="line">    end</div>
<div class="line">    Teleprompter-&gt;&gt;StudentProgram: Assign selected demos to predictors</div>
<div class="line">    StudentProgram--&gt;&gt;CompiledProgram: Create compiled version</div>
<div class="line">    Teleprompter--&gt;&gt;User: Return CompiledProgram</div>
</div><!-- fragment --><p><b>Relevant Code Files:</b></p>
<ul>
<li><code>dspy/teleprompt/teleprompt.py</code>: Defines the base <code>Teleprompter</code> class.</li>
<li><code>dspy/teleprompt/bootstrap.py</code>: Contains the implementation for <code>BootstrapFewShot</code>. Key methods include <code>compile</code> (orchestrates the process) and <code>_bootstrap_one_example</code> (handles running the teacher and checking the metric for a single training example).</li>
</ul>
<div class="fragment"><div class="line"><span class="comment"># Simplified view from dspy/teleprompt/bootstrap.py</span></div>
<div class="line"> </div>
<div class="line"><span class="comment"># ... imports ...</span></div>
<div class="line"><span class="keyword">from</span> .teleprompt <span class="keyword">import</span> Teleprompter</div>
<div class="line"><span class="keyword">from</span> .vanilla <span class="keyword">import</span> LabeledFewShot <span class="comment"># Used for teacher setup if labeled demos are needed</span></div>
<div class="line"><span class="keyword">import</span> dspy</div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>BootstrapFewShot(Teleprompter):</div>
<div class="line">    <span class="keyword">def </span>__init__(self, metric=None, max_bootstrapped_demos=4, ...):</div>
<div class="line">        self.metric = metric</div>
<div class="line">        self.max_bootstrapped_demos = max_bootstrapped_demos</div>
<div class="line">        <span class="comment"># ... other initializations ...</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>compile(self, student, *, teacher=None, trainset):</div>
<div class="line">        self.trainset = trainset</div>
<div class="line">        self._prepare_student_and_teacher(student, teacher) <span class="comment"># Sets up self.student and self.teacher</span></div>
<div class="line">        self._prepare_predictor_mappings() <span class="comment"># Links student predictors to teacher predictors</span></div>
<div class="line">        self._bootstrap() <span class="comment"># Runs the core bootstrapping logic</span></div>
<div class="line"> </div>
<div class="line">        self.student = self._train() <span class="comment"># Assigns collected demos to the student</span></div>
<div class="line">        self.student._compiled = <span class="keyword">True</span></div>
<div class="line">        <span class="keywordflow">return</span> self.student</div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>_bootstrap(self):</div>
<div class="line">        <span class="comment"># ... setup ...</span></div>
<div class="line">        self.name2traces = {name: [] <span class="keywordflow">for</span> name <span class="keywordflow">in</span> self.name2predictor} <span class="comment"># Store successful traces per predictor</span></div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">for</span> example_idx, example <span class="keywordflow">in</span> enumerate(tqdm.tqdm(self.trainset)):</div>
<div class="line">            <span class="comment"># ... logic to stop early if enough demos found ...</span></div>
<div class="line">            success = self._bootstrap_one_example(example, round_idx=0) <span class="comment"># Try to get a demo from this example</span></div>
<div class="line">            <span class="comment"># ... potentially multiple rounds ...</span></div>
<div class="line"> </div>
<div class="line">        <span class="comment"># ... logging ...</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>_bootstrap_one_example(self, example, round_idx=0):</div>
<div class="line">        <span class="comment"># ... setup teacher context (e.g., temperature) ...</span></div>
<div class="line">        <span class="keywordflow">try</span>:</div>
<div class="line">            <span class="keyword">with</span> dspy.settings.context(trace=[], **self.teacher_settings):</div>
<div class="line">                <span class="comment"># Optionally modify teacher LM settings for exploration</span></div>
<div class="line">                <span class="comment"># ...</span></div>
<div class="line">                <span class="comment"># Run the teacher program</span></div>
<div class="line">                prediction = self.teacher(**example.inputs())</div>
<div class="line">                trace = dspy.settings.trace <span class="comment"># Get the execution trace</span></div>
<div class="line"> </div>
<div class="line">                <span class="comment"># Evaluate the prediction using the metric</span></div>
<div class="line">                <span class="keywordflow">if</span> self.metric:</div>
<div class="line">                    metric_val = self.metric(example, prediction, trace)</div>
<div class="line">                    <span class="comment"># Determine success based on metric value/threshold</span></div>
<div class="line">                    success = bool(metric_val) <span class="comment"># Simplified</span></div>
<div class="line">                <span class="keywordflow">else</span>:</div>
<div class="line">                    success = <span class="keyword">True</span> <span class="comment"># Assume success if no metric provided</span></div>
<div class="line">        <span class="keywordflow">except</span> Exception:</div>
<div class="line">            success = <span class="keyword">False</span></div>
<div class="line">            <span class="comment"># ... error handling ...</span></div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> success:</div>
<div class="line">            <span class="comment"># If successful, extract demos from the trace</span></div>
<div class="line">            <span class="keywordflow">for</span> step <span class="keywordflow">in</span> trace:</div>
<div class="line">                predictor, inputs, outputs = step</div>
<div class="line">                demo = dspy.Example(augmented=<span class="keyword">True</span>, **inputs, **outputs)</div>
<div class="line">                <span class="keywordflow">try</span>:</div>
<div class="line">                    predictor_name = self.predictor2name[id(predictor)]</div>
<div class="line">                    <span class="comment"># Store the successful demo example</span></div>
<div class="line">                    self.name2traces[predictor_name].append(demo)</div>
<div class="line">                <span class="keywordflow">except</span> KeyError:</div>
<div class="line">                    <span class="keywordflow">continue</span> <span class="comment"># Handle potential issues finding the predictor</span></div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">return</span> success</div>
<div class="line"> </div>
<div class="line">    <span class="keyword">def </span>_train(self):</div>
<div class="line">        <span class="comment"># Assign the collected demos to the student&#39;s predictors</span></div>
<div class="line">        <span class="keywordflow">for</span> name, predictor <span class="keywordflow">in</span> self.student.named_predictors():</div>
<div class="line">            demos_for_predictor = self.name2traces[name][:self.max_bootstrapped_demos]</div>
<div class="line">            <span class="comment"># Potentially mix with labeled demos if configured</span></div>
<div class="line">            <span class="comment"># ...</span></div>
<div class="line">            predictor.demos = demos_for_predictor <span class="comment"># Assign the demos!</span></div>
<div class="line">        <span class="keywordflow">return</span> self.student</div>
</div><!-- fragment --><p>This simplified view shows the core loop: run the teacher, check the metric, collect successful traces as demos, and finally assign those demos to the student program.</p>
<h2><a class="anchor" id="autotoc_md1671"></a>
Conclusion</h2>
<p>You've now learned about DSPy's <b>Teleprompters / Optimizers</b>, the powerful tools for automating prompt engineering!</p>
<ul>
<li>Teleprompters act like <b>coaches</b>, automatically tuning your DSPy programs (students).</li>
<li>They optimize parameters like <b>instructions</b> and <b>few-shot examples (demos)</b>.</li>
<li>They require a <b>student program</b>, a <b>training dataset</b>, and a <b>metric</b> function.</li>
<li>We saw how <code>BootstrapFewShot</code> automatically finds effective few-shot examples by running a teacher model and collecting successful execution traces.</li>
<li>The result of <code>teleprompter.compile()</code> is an <b>optimized program</b> instance, ready to be used or evaluated further.</li>
</ul>
<p>Teleprompters save you from the tedious process of manual tuning, allowing you to build high-performing LM-based programs more efficiently.</p>
<p>Now that we understand how to build, evaluate, and automatically optimize DSPy programs, how can we make them interact smoothly with different data formats or models, especially when integrating with other systems? That's where <b>Adapters</b> come in.</p>
<p><b>Next:</b> <a class="el" href="../../d3/dc3/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2DSPy_209__adapter.html">Chapter 9: Adapter</a></p>
<hr  />
<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a> </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
