#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
<!-- HTML header for doxygen 1.9.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ResilientDB: 05_worker</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen_html_style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../logo.png"/></td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dc/d91/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Celery_205__worker.html','../../'); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">05_worker</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="autotoc_md1048"></a>
autotoc_md1048</h2>
<p>layout: default title: "Worker" parent: "Celery" </p>
<h2><a class="anchor" id="autotoc_md1049"></a>
nav_order: 5</h2>
<h1><a class="anchor" id="autotoc_md1050"></a>
Chapter 5: Worker - The Task Doer</h1>
<p>In <a class="el" href="../../d3/dd5/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Celery_204__broker__connection____amqp__.html">Chapter 4: Broker Connection (AMQP)</a>, we learned how Celery uses a message broker, like a postal service, to send task messages. When you call <code>add.delay(2, 2)</code>, a message asking to run the <code>add</code> task with arguments <code>(2, 2)</code> gets dropped into a mailbox (the broker queue).</p>
<p>But who actually checks that mailbox, picks up the message, and performs the addition? That's the job of the <b>Celery Worker</b>.</p>
<h2><a class="anchor" id="autotoc_md1051"></a>
What Problem Does the Worker Solve?</h2>
<p>Imagine our workshop analogy again. You've defined the blueprint for a job (<a class="el" href="../../d5/db8/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Celery_203__task.html">Task</a>) and you've dropped the work order into the central inbox (<a class="el" href="../../d3/dd5/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Celery_204__broker__connection____amqp__.html">Broker Connection (AMQP)</a>). Now you need an actual employee or a machine to:</p>
<ol type="1">
<li>Look in the inbox for new work orders.</li>
<li>Pick up an order.</li>
<li>Follow the instructions (run the task code).</li>
<li>Maybe put the finished product (the result) somewhere specific.</li>
<li>Mark the order as complete.</li>
</ol>
<p>The <b>Celery Worker</b> is that employee or machine. It's a separate program (process) that you run, whose sole purpose is to execute the tasks you send to the broker. Without a worker running, your task messages would just sit in the queue forever, waiting for someone to process them.</p>
<h2><a class="anchor" id="autotoc_md1052"></a>
Starting Your First Worker</h2>
<p>Running a worker is typically done from your command line or terminal. You need to tell the worker where to find your <a class="el" href="../../d3/d58/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Celery_201__celery__app.html">Celery App</a> instance (which holds the configuration, including the broker address and the list of known tasks).</p>
<p>Assuming you have:</p><ul>
<li>A file <code>celery_app.py</code> containing your <code>app = Celery(...)</code> instance.</li>
<li>A file <code>tasks.py</code> containing your task definitions (like <code>add</code> and <code>send_welcome_email</code>) decorated with <code>@app.task</code>.</li>
<li>Your message broker (e.g., Redis or RabbitMQ) running.</li>
</ul>
<p>You can start a worker like this:</p>
<div class="fragment"><div class="line"># In your terminal, in the same directory as celery_app.py and tasks.py</div>
<div class="line"># Make sure your Python environment has celery and the broker driver installed</div>
<div class="line"># (e.g., pip install celery redis)</div>
<div class="line"> </div>
<div class="line">celery -A celery_app worker --loglevel=info</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ul>
<li><code>celery</code>: This is the main Celery command-line program.</li>
<li><code>-A celery_app</code>: The <code>-A</code> flag (or <code>--app</code>) tells Celery where to find your <code>Celery</code> app instance. <code>celery_app</code> refers to the <code>celery_app.py</code> file (or module) and implies Celery should look for an instance named <code>app</code> inside it.</li>
<li><code>worker</code>: This specifies that you want to run the worker component.</li>
<li><code>--loglevel=info</code>: This sets the logging level. <code>info</code> is a good starting point, showing you when the worker connects, finds tasks, and executes them. Other levels include <code>debug</code> (more verbose), <code>warning</code>, <code>error</code>, and <code>critical</code>.</li>
</ul>
<p><b>What You'll See:</b></p>
<p>When the worker starts successfully, you'll see a banner like this (details may vary):</p>
<div class="fragment"><div class="line"> -------------- celery@yourhostname v5.x.x (stars)</div>
<div class="line">--- ***** -----</div>
<div class="line">-- ******* ---- Linux-5.15.0...-generic-x86_64-with-... 2023-10-27 10:00:00</div>
<div class="line">- *** --- * ---</div>
<div class="line">- ** ---------- [config]</div>
<div class="line">- ** ---------- .&gt; app:         tasks:0x7f...</div>
<div class="line">- ** ---------- .&gt; transport:   redis://localhost:6379/0</div>
<div class="line">- ** ---------- .&gt; results:     redis://localhost:6379/0</div>
<div class="line">- *** --- * --- .&gt; concurrency: 8 (prefork)</div>
<div class="line">-- ******* ---- .&gt; task events: OFF (enable -E to monitor tasks in this worker)</div>
<div class="line">--- ***** -----</div>
<div class="line"> -------------- [queues]</div>
<div class="line">                .&gt; celery           exchange=celery(direct) key=celery</div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line">[tasks]</div>
<div class="line">  . tasks.add</div>
<div class="line">  . tasks.send_welcome_email</div>
<div class="line"> </div>
<div class="line">[2023-10-27 10:00:01,000: INFO/MainProcess] Connected to redis://localhost:6379/0</div>
<div class="line">[2023-10-27 10:00:01,050: INFO/MainProcess] mingle: searching for neighbors</div>
<div class="line">[2023-10-27 10:00:02,100: INFO/MainProcess] mingle: all alone</div>
<div class="line">[2023-10-27 10:00:02,150: INFO/MainProcess] celery@yourhostname ready.</div>
</div><!-- fragment --><p><b>Key Parts of the Banner:</b></p>
<ul>
<li><code>celery@yourhostname</code>: The unique name of this worker instance.</li>
<li><code>transport</code>: The broker URL it connected to (from your app config).</li>
<li><code>results</code>: The result backend URL (if configured).</li>
<li><code>concurrency</code>: How many tasks this worker can potentially run at once (defaults to the number of CPU cores) and the execution pool type (<code>prefork</code> is common). We'll touch on this later.</li>
<li><code>queues</code>: The specific "mailboxes" (queues) the worker is listening to. <code>celery</code> is the default queue name.</li>
<li><code>[tasks]</code>: A list of all the tasks the worker discovered (like our <code>tasks.add</code> and <code>tasks.send_welcome_email</code>). If your tasks don't show up here, the worker won't be able to run them!</li>
</ul>
<p>The final <code>celery@yourhostname ready.</code> message means the worker is connected and waiting for jobs!</p>
<h2><a class="anchor" id="autotoc_md1053"></a>
What the Worker Does</h2>
<p>Now that the worker is running, let's trace what happens when you send a task (e.g., from <code>run_tasks.py</code> in <a class="el" href="../../d5/db8/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Celery_203__task.html">Chapter 3: Task</a>):</p>
<ol type="1">
<li><b>Waiting:</b> The worker is connected to the broker, listening on the <code>celery</code> queue.</li>
<li><b>Message Arrival:</b> Your <code>add.delay(5, 7)</code> call sends a message to the <code>celery</code> queue on the broker. The broker notifies the worker.</li>
<li><b>Receive &amp; Decode:</b> The worker receives the raw message. It decodes it to find the task name (<code>tasks.add</code>), the arguments (<code>(5, 7)</code>), and other info (like a unique task ID).</li>
<li><b>Find Task Code:</b> The worker looks up the name <code>tasks.add</code> in its internal registry (populated when it started) to find the actual Python function <code>add</code> defined in <code>tasks.py</code>.</li>
<li><b>Execute:</b> The worker executes the function: <code>add(5, 7)</code>.<ul>
<li>You will see the <code>print</code> statements from your task function appear in the <em>worker's</em> terminal output: <code>text [2023-10-27 10:05:00,100: INFO/ForkPoolWorker-1] Task tasks.add[some-task-id] received Task 'add' starting with (5, 7) Task 'add' finished with result: 12 [2023-10-27 10:05:05,150: INFO/ForkPoolWorker-1] Task tasks.add[some-task-id] succeeded in 5.05s: 12 </code></li>
</ul>
</li>
<li><b>Store Result (Optional):</b> If a <a class="el" href="../../d3/d55/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Celery_206__result__backend.html">Result Backend</a> is configured, the worker takes the return value (<code>12</code>) and sends it to the backend, associating it with the task's unique ID.</li>
<li><b>Acknowledge:</b> The worker sends an "acknowledgement" (ack) back to the broker. This tells the broker, "I finished processing this message successfully, you can delete it from the queue." This ensures tasks aren't lost if a worker crashes mid-execution (the message would remain on the queue for another worker to pick up).</li>
<li><b>Wait Again:</b> The worker goes back to waiting for the next message.</li>
</ol>
<h2><a class="anchor" id="autotoc_md1054"></a>
Running Multiple Workers and Concurrency</h2>
<ul>
<li><b>Multiple Workers:</b> You can start multiple worker processes by running the <code>celery worker</code> command again, perhaps on different machines or in different terminals on the same machine. They will all connect to the same broker and pull tasks from the queue, allowing you to process tasks in parallel and scale your application.</li>
<li><b>Concurrency within a Worker:</b> A single worker process can often handle more than one task concurrently. Celery achieves this using <em>execution pools</em>.<ul>
<li><b>Prefork (Default):</b> The worker starts several child <em>processes</em>. Each child process handles one task at a time. The <code>-c</code> (or <code>--concurrency</code>) flag controls the number of child processes (default is the number of CPU cores). This is good for CPU-bound tasks.</li>
<li><b>Eventlet/Gevent:</b> Uses <em>green threads</em> (lightweight concurrency managed by libraries like eventlet or gevent). A single worker process can handle potentially hundreds or thousands of tasks concurrently, especially if the tasks are I/O-bound (e.g., waiting for network requests). You select these using the <code>-P</code> flag: <code>celery -A celery_app worker -P eventlet -c 1000</code>. Requires installing the respective library (<code>pip install eventlet</code> or <code>pip install gevent</code>).</li>
<li><b>Solo:</b> Executes tasks one after another in the main worker process. Useful for debugging. <code>-P solo</code>.</li>
<li><b>Threads:</b> Uses regular OS threads. <code>-P threads</code>. Less common for Celery tasks due to Python's Global Interpreter Lock (GIL) limitations for CPU-bound tasks, but can be useful for I/O-bound tasks.</li>
</ul>
</li>
</ul>
<p>For beginners, sticking with the default <b>prefork</b> pool is usually fine. Just know that the worker can likely handle multiple tasks simultaneously.</p>
<h2><a class="anchor" id="autotoc_md1055"></a>
How It Works Internally (Simplified)</h2>
<p>Let's visualize the worker's main job: processing a single task.</p>
<ol type="1">
<li><b>Startup:</b> The <code>celery worker</code> command starts the main worker process. It loads the <code>Celery App</code>, reads the configuration (<code>broker_url</code>, tasks to import, etc.).</li>
<li><b>Connect &amp; Listen:</b> The worker establishes a connection to the message broker and tells it, "I'm ready to consume messages from the 'celery' queue."</li>
<li><b>Message Delivery:</b> The broker sees a message for the 'celery' queue (sent by <code>add.delay(5, 7)</code>) and delivers it to the connected worker.</li>
<li><b>Consumer Receives:</b> The worker's internal "Consumer" component receives the message.</li>
<li><b>Task Dispatch:</b> The Consumer decodes the message, identifies the task (<code>tasks.add</code>), and finds the arguments (<code>(5, 7)</code>). It then hands this off to the configured execution pool (e.g., prefork).</li>
<li><b>Pool Execution:</b> The pool (e.g., a child process in the prefork pool) gets the task function and arguments and executes <code>add(5, 7)</code>.</li>
<li><b>Result Return:</b> The pool process finishes execution and returns the result (<code>12</code>) back to the main worker process.</li>
<li><b>Result Handling (Optional):</b> The main worker process, if a <a class="el" href="../../d3/d55/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Celery_206__result__backend.html">Result Backend</a> is configured, sends the result (<code>12</code>) and task ID to the backend store.</li>
<li><b>Acknowledgement:</b> The main worker process sends an "ack" message back to the broker, confirming the task message was successfully processed. The broker then deletes the message.</li>
</ol>
<div class="fragment"><div class="line">sequenceDiagram</div>
<div class="line">    participant CLI as Terminal (celery worker)</div>
<div class="line">    participant WorkerMain as Worker Main Process</div>
<div class="line">    participant App as Celery App Instance</div>
<div class="line">    participant Broker as Message Broker</div>
<div class="line">    participant Pool as Execution Pool (e.g., Prefork Child)</div>
<div class="line">    participant TaskCode as Your Task Function (add)</div>
<div class="line"> </div>
<div class="line">    CLI-&gt;&gt;WorkerMain: Start celery -A celery_app worker</div>
<div class="line">    WorkerMain-&gt;&gt;App: Load App &amp; Config (broker_url, tasks)</div>
<div class="line">    WorkerMain-&gt;&gt;Broker: Connect &amp; Listen on &#39;celery&#39; queue</div>
<div class="line"> </div>
<div class="line">    Broker--&gt;&gt;WorkerMain: Deliver Message (&#39;tasks.add&#39;, (5, 7), task_id)</div>
<div class="line">    WorkerMain-&gt;&gt;WorkerMain: Decode Message</div>
<div class="line">    WorkerMain-&gt;&gt;Pool: Request Execute add(5, 7) with task_id</div>
<div class="line">    Pool-&gt;&gt;TaskCode: Run add(5, 7)</div>
<div class="line">    TaskCode--&gt;&gt;Pool: Return 12</div>
<div class="line">    Pool--&gt;&gt;WorkerMain: Result=12 for task_id</div>
<div class="line">    Note over WorkerMain: (Optionally) Store 12 in Result Backend</div>
<div class="line">    WorkerMain-&gt;&gt;Broker: Acknowledge task_id is complete</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md1056"></a>
Code Dive: Where Worker Logic Lives</h2>
<ul>
<li><b>Command Line Entry Point (<code>celery/bin/worker.py</code>):</b> This script handles parsing the command-line arguments (<code>-A</code>, <code>-l</code>, <code>-c</code>, <code>-P</code>, etc.) when you run <code>celery worker ...</code>. It ultimately creates and starts a <code>WorkController</code> instance. (See <code>worker()</code> function in the file).</li>
<li><b>Main Worker Class (<code>celery/worker/worker.py</code>):</b> The <code>WorkController</code> class is the heart of the worker. It manages all the different components (like the pool, consumer, timer, etc.) using a system called "bootsteps". It handles the overall startup, shutdown, and coordination. (See <code>WorkController</code> class).</li>
<li><b>Message Handling (<code>celery/worker/consumer/consumer.py</code>):</b> The <code>Consumer</code> class (specifically its <code>Blueprint</code> and steps like <code>Tasks</code> and <code>Evloop</code>) is responsible for the core loop of fetching messages from the broker via the connection, decoding them, and dispatching them to the execution pool using task strategies. (See <code>Consumer.create_task_handler</code>).</li>
<li><b>Execution Pools (<code>celery/concurrency/</code>):</b> Modules like <code>prefork.py</code>, <code>solo.py</code>, <code>eventlet.py</code>, <code>gevent.py</code> implement the different concurrency models (<code>-P</code> flag). The <code>WorkController</code> selects and manages one of these pools.</li>
</ul>
<p>A highly simplified conceptual view of the core message processing logic within the <code>Consumer</code>:</p>
<div class="fragment"><div class="line"><span class="comment"># Conceptual loop inside the Consumer (highly simplified)</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">def </span>message_handler(message):</div>
<div class="line">    <span class="keywordflow">try</span>:</div>
<div class="line">        <span class="comment"># 1. Decode message (task name, args, kwargs, id, etc.)</span></div>
<div class="line">        task_name, args, kwargs, task_id = decode_message(message.body, message.headers)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 2. Find the registered task function</span></div>
<div class="line">        task_func = app.tasks[task_name]</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 3. Prepare execution request for the pool</span></div>
<div class="line">        request = TaskRequest(task_id, task_name, task_func, args, kwargs)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># 4. Send request to the pool for execution</span></div>
<div class="line">        <span class="comment">#    (Pool runs request.execute() which calls task_func(*args, **kwargs))</span></div>
<div class="line">        pool.apply_async(request.execute, accept_callback=task_succeeded, ...)</div>
<div class="line"> </div>
<div class="line">    <span class="keywordflow">except</span> Exception <span class="keyword">as</span> e:</div>
<div class="line">        <span class="comment"># Handle errors (e.g., unknown task, decoding error)</span></div>
<div class="line">        log_error(e)</div>
<div class="line">        message.reject() <span class="comment"># Tell broker it failed</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">def </span>task_succeeded(task_id, retval):</div>
<div class="line">    <span class="comment"># Called by the pool when task finishes successfully</span></div>
<div class="line">    <span class="comment"># 5. Store result (optional)</span></div>
<div class="line">    <span class="keywordflow">if</span> app.backend:</div>
<div class="line">        app.backend.store_result(task_id, retval, status=<span class="stringliteral">&#39;SUCCESS&#39;</span>)</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 6. Acknowledge message to broker</span></div>
<div class="line">    message.ack()</div>
<div class="line"> </div>
<div class="line"><span class="comment"># --- Setup ---</span></div>
<div class="line"><span class="comment"># Worker connects to broker and registers message_handler</span></div>
<div class="line"><span class="comment"># for incoming messages on the subscribed queue(s)</span></div>
<div class="line">connection.consume(queue_name, callback=message_handler)</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Start the event loop to wait for messages</span></div>
<div class="line">connection.drain_events()</div>
</div><!-- fragment --><p>This illustrates the fundamental cycle: receive -&gt; decode -&gt; find task -&gt; execute via pool -&gt; handle result -&gt; acknowledge. The actual code involves much more detail regarding error handling, state management, different protocols, rate limiting, etc., managed through the bootstep system.</p>
<h2><a class="anchor" id="autotoc_md1057"></a>
Conclusion</h2>
<p>You've now met the <b>Celery Worker</b>, the essential component that actually <em>runs</em> your tasks.</p>
<ul>
<li>It's a <b>separate process</b> you start from the command line (<code>celery worker</code>).</li>
<li>It connects to the <b>broker</b> using the configuration from your <b>Celery App</b>.</li>
<li>It <b>listens</b> for task messages on queues.</li>
<li>It <b>executes</b> the corresponding task code when a message arrives.</li>
<li>It handles <b>concurrency</b> using execution pools (like prefork, eventlet, gevent).</li>
<li>It <b>acknowledges</b> messages to the broker upon successful completion.</li>
</ul>
<p>Without workers, Celery tasks would never get done. But what happens when a task finishes? What if it returns a value, like our <code>add</code> task returning <code>12</code>? How can your original application find out the result? That's where the Result Backend comes in.</p>
<p><b>Next:</b> <a class="el" href="../../d3/d55/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Celery_206__result__backend.html">Chapter 6: Result Backend</a></p>
<hr  />
<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a> </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
