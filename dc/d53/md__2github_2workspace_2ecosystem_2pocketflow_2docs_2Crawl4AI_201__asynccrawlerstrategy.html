#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
<!-- HTML header for doxygen 1.9.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ResilientDB: 01_asynccrawlerstrategy</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen_html_style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../logo.png"/></td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dc/d53/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_201__asynccrawlerstrategy.html','../../'); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">01_asynccrawlerstrategy</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="autotoc_md1376"></a>
autotoc_md1376</h2>
<p>layout: default title: "AsyncCrawlerStrategy" parent: "Crawl4AI" </p>
<h2><a class="anchor" id="autotoc_md1377"></a>
nav_order: 1</h2>
<h1><a class="anchor" id="autotoc_md1378"></a>
Chapter 1: How We Fetch Webpages - AsyncCrawlerStrategy</h1>
<p>Welcome to the Crawl4AI tutorial series! Our goal is to build intelligent agents that can understand and extract information from the web. The very first step in this process is actually <em>getting</em> the content from a webpage. This chapter explains how Crawl4AI handles that fundamental task.</p>
<p>Imagine you need to pick up a package from a specific address. How do you get there and retrieve it?</p><ul>
<li>You could send a <b>simple, fast drone</b> that just grabs the package off the porch (if it's easily accessible). This is quick but might fail if the package is inside or requires a signature.</li>
<li>Or, you could send a <b>full delivery truck with a driver</b>. The driver can ring the bell, wait, sign for the package, and even handle complex instructions. This is more versatile but takes more time and resources.</li>
</ul>
<p>In Crawl4AI, the <code>AsyncCrawlerStrategy</code> is like choosing your delivery vehicle. It defines <em>how</em> the crawler fetches the raw content (like the HTML, CSS, and maybe JavaScript results) of a webpage.</p>
<h2><a class="anchor" id="autotoc_md1379"></a>
What Exactly is AsyncCrawlerStrategy?</h2>
<p><code>AsyncCrawlerStrategy</code> is a core concept in Crawl4AI that represents the <b>method</b> or <b>technique</b> used to download the content of a given URL. Think of it as a blueprint: it specifies <em>that</em> we need a way to fetch content, but the specific <em>details</em> of how it's done can vary.</p>
<p>This "blueprint" approach is powerful because it allows us to swap out the fetching mechanism depending on our needs, without changing the rest of our crawling logic.</p>
<h2><a class="anchor" id="autotoc_md1380"></a>
The Default: AsyncPlaywrightCrawlerStrategy (The Delivery Truck)</h2>
<p>By default, Crawl4AI uses <code>AsyncPlaywrightCrawlerStrategy</code>. This strategy uses a real, automated web browser engine (like Chrome, Firefox, or WebKit) behind the scenes.</p>
<p><b>Why use a full browser?</b></p>
<ul>
<li><b>Handles JavaScript:</b> Modern websites rely heavily on JavaScript to load content, change the layout, or fetch data after the initial page load. <code>AsyncPlaywrightCrawlerStrategy</code> runs this JavaScript, just like your normal browser does.</li>
<li><b>Simulates User Interaction:</b> It can wait for elements to appear, handle dynamic content, and see the page <em>after</em> scripts have run.</li>
<li><b>Gets the "Final" View:</b> It fetches the content as a user would see it in their browser.</li>
</ul>
<p>This is our "delivery truck" – powerful and capable of handling complex websites. However, like a real truck, it's slower and uses more memory and CPU compared to simpler methods.</p>
<p>You generally don't need to <em>do</em> anything to use it, as it's the default! When you start Crawl4AI, it picks this strategy automatically.</p>
<h2><a class="anchor" id="autotoc_md1381"></a>
Another Option: AsyncHTTPCrawlerStrategy (The Delivery Drone)</h2>
<p>Crawl4AI also offers <code>AsyncHTTPCrawlerStrategy</code>. This strategy is much simpler. It directly requests the URL and downloads the <em>initial</em> HTML source code that the web server sends back.</p>
<p><b>Why use this simpler strategy?</b></p>
<ul>
<li><b>Speed:</b> It's significantly faster because it doesn't need to start a browser, render the page, or execute JavaScript.</li>
<li><b>Efficiency:</b> It uses much less memory and CPU.</li>
</ul>
<p>This is our "delivery drone" – super fast and efficient for simple tasks.</p>
<p><b>What's the catch?</b></p>
<ul>
<li><b>No JavaScript:</b> It won't run any JavaScript on the page. If content is loaded dynamically by scripts, this strategy will likely miss it.</li>
<li><b>Basic HTML Only:</b> You get the raw HTML source, not necessarily what a user <em>sees</em> after the browser processes everything.</li>
</ul>
<p>This strategy is great for websites with simple, static HTML content or when you only need the basic structure and metadata very quickly.</p>
<h2><a class="anchor" id="autotoc_md1382"></a>
Why Have Different Strategies? (The Power of Abstraction)</h2>
<p>Having <code>AsyncCrawlerStrategy</code> as a distinct concept offers several advantages:</p>
<ol type="1">
<li><b>Flexibility:</b> You can choose the best tool for the job. Need to crawl complex, dynamic sites? Use the default <code>AsyncPlaywrightCrawlerStrategy</code>. Need to quickly fetch basic HTML from thousands of simple pages? Switch to <code>AsyncHTTPCrawlerStrategy</code>.</li>
<li><b>Maintainability:</b> The logic for <em>fetching</em> content is kept separate from the logic for <em>processing</em> it.</li>
<li><b>Extensibility:</b> Advanced users could even create their <em>own</em> custom strategies for specialized fetching needs (though that's beyond this beginner tutorial).</li>
</ol>
<h2><a class="anchor" id="autotoc_md1383"></a>
How It Works Conceptually</h2>
<p>When you ask Crawl4AI to crawl a URL, the main <code>AsyncWebCrawler</code> doesn't fetch the content itself. Instead, it delegates the task to the currently selected <code>AsyncCrawlerStrategy</code>.</p>
<p>Here's a simplified flow:</p>
<div class="fragment"><div class="line">sequenceDiagram</div>
<div class="line">    participant C as AsyncWebCrawler</div>
<div class="line">    participant S as AsyncCrawlerStrategy</div>
<div class="line">    participant W as Website</div>
<div class="line"> </div>
<div class="line">    C-&gt;&gt;S: Please crawl(&quot;https://example.com&quot;)</div>
<div class="line">    Note over S: I&#39;m using my method (e.g., Browser or HTTP)</div>
<div class="line">    S-&gt;&gt;W: Request Page Content</div>
<div class="line">    W--&gt;&gt;S: Return Raw Content (HTML, etc.)</div>
<div class="line">    S--&gt;&gt;C: Here&#39;s the result (AsyncCrawlResponse)</div>
</div><!-- fragment --><p>The <code>AsyncWebCrawler</code> only needs to know how to talk to <em>any</em> strategy through a common interface (the <code>crawl</code> method). The strategy handles the specific details of the fetching process.</p>
<h2><a class="anchor" id="autotoc_md1384"></a>
Using the Default Strategy (You're Already Doing It!)</h2>
<p>Let's see how you use the default <code>AsyncPlaywrightCrawlerStrategy</code> without even needing to specify it.</p>
<div class="fragment"><div class="line"><span class="comment"># main_example.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="comment"># When you create AsyncWebCrawler without specifying a strategy,</span></div>
<div class="line">    <span class="comment"># it automatically uses AsyncPlaywrightCrawlerStrategy!</span></div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        print(<span class="stringliteral">&quot;Crawler is ready using the default strategy (Playwright).&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># Let&#39;s crawl a simple page that just returns HTML</span></div>
<div class="line">        <span class="comment"># We use CacheMode.BYPASS to ensure we fetch it fresh each time for this demo.</span></div>
<div class="line">        config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)</div>
<div class="line">        result = await crawler.arun(</div>
<div class="line">            url=<span class="stringliteral">&quot;https://httpbin.org/html&quot;</span>,</div>
<div class="line">            config=config</div>
<div class="line">        )</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> result.success:</div>
<div class="line">            print(<span class="stringliteral">&quot;\nSuccessfully fetched content!&quot;</span>)</div>
<div class="line">            <span class="comment"># The strategy fetched the raw HTML.</span></div>
<div class="line">            <span class="comment"># AsyncWebCrawler then processes it (more on that later).</span></div>
<div class="line">            print(f<span class="stringliteral">&quot;First 100 chars of fetched HTML: {result.html[:100]}...&quot;</span>)</div>
<div class="line">        <span class="keywordflow">else</span>:</div>
<div class="line">            print(f<span class="stringliteral">&quot;\nFailed to fetch content: {result.error_message}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
<div class="ttc" id="anamespacemain_html"><div class="ttname"><a href="../../d2/dc1/namespacemain.html">main</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/dba/main_8py_source.html#l00001">main.py:1</a></div></div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ol type="1">
<li>We import <code>AsyncWebCrawler</code> and supporting classes.</li>
<li>We create an instance of <code>AsyncWebCrawler()</code> inside an <code>async with</code> block (this handles setup and cleanup). Since we didn't tell it <em>which</em> strategy to use, it defaults to <code>AsyncPlaywrightCrawlerStrategy</code>.</li>
<li>We call <code>crawler.arun()</code> to crawl the URL. Under the hood, the <code>AsyncPlaywrightCrawlerStrategy</code> starts a browser, navigates to the page, gets the content, and returns it.</li>
<li>We print the first part of the fetched HTML from the <code>result</code>.</li>
</ol>
<h2><a class="anchor" id="autotoc_md1385"></a>
Explicitly Choosing the HTTP Strategy</h2>
<p>What if you know the page is simple and want the speed of the "delivery drone"? You can explicitly tell <code>AsyncWebCrawler</code> to use <code>AsyncHTTPCrawlerStrategy</code>.</p>
<div class="fragment"><div class="line"><span class="comment"># http_strategy_example.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode</div>
<div class="line"><span class="comment"># Import the specific strategies we want to use</span></div>
<div class="line"><span class="keyword">from</span> crawl4ai.async_crawler_strategy <span class="keyword">import</span> AsyncHTTPCrawlerStrategy</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="comment"># 1. Create an instance of the strategy you want</span></div>
<div class="line">    http_strategy = AsyncHTTPCrawlerStrategy()</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># 2. Pass the strategy instance when creating the AsyncWebCrawler</span></div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler(crawler_strategy=http_strategy) <span class="keyword">as</span> crawler:</div>
<div class="line">        print(<span class="stringliteral">&quot;Crawler is ready using the explicit HTTP strategy.&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># Crawl the same simple page</span></div>
<div class="line">        config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)</div>
<div class="line">        result = await crawler.arun(</div>
<div class="line">            url=<span class="stringliteral">&quot;https://httpbin.org/html&quot;</span>,</div>
<div class="line">            config=config</div>
<div class="line">        )</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> result.success:</div>
<div class="line">            print(<span class="stringliteral">&quot;\nSuccessfully fetched content using HTTP strategy!&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;First 100 chars of fetched HTML: {result.html[:100]}...&quot;</span>)</div>
<div class="line">        <span class="keywordflow">else</span>:</div>
<div class="line">            print(f<span class="stringliteral">&quot;\nFailed to fetch content: {result.error_message}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ol type="1">
<li>We now also import <code>AsyncHTTPCrawlerStrategy</code>.</li>
<li>We create an instance: <code>http_strategy = AsyncHTTPCrawlerStrategy()</code>.</li>
<li>We pass this instance to the <code>AsyncWebCrawler</code> constructor: <code>AsyncWebCrawler(crawler_strategy=http_strategy)</code>.</li>
<li>The rest of the code is the same, but now <code>crawler.arun()</code> will use the faster, simpler HTTP GET request method defined by <code>AsyncHTTPCrawlerStrategy</code>.</li>
</ol>
<p>For a simple page like <code>httpbin.org/html</code>, both strategies will likely return the same HTML content, but the HTTP strategy would generally be faster and use fewer resources. On a complex JavaScript-heavy site, the HTTP strategy might fail to get the full content, while the Playwright strategy would handle it correctly.</p>
<h2><a class="anchor" id="autotoc_md1386"></a>
A Glimpse Under the Hood</h2>
<p>You don't <em>need</em> to know the deep internals to use the strategies, but it helps to understand the structure. Inside the <code>crawl4ai</code> library, you'd find a file like <code>async_crawler_strategy.py</code>.</p>
<p>It defines the "blueprint" (an Abstract Base Class):</p>
<div class="fragment"><div class="line"><span class="comment"># Simplified from async_crawler_strategy.py</span></div>
<div class="line"><span class="keyword">from</span> abc <span class="keyword">import</span> ABC, abstractmethod</div>
<div class="line"><span class="keyword">from</span> .models <span class="keyword">import</span> AsyncCrawlResponse <span class="comment"># Defines the structure of the result</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>AsyncCrawlerStrategy(ABC):</div>
<div class="line">    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="stringliteral">    Abstract base class for crawler strategies.</span></div>
<div class="line"><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line">    <span class="preprocessor">@abstractmethod</span></div>
<div class="line">    <span class="keyword">async def </span>crawl(self, url: str, **kwargs) -&gt; AsyncCrawlResponse:</div>
<div class="line">        <span class="stringliteral">&quot;&quot;&quot;Fetch content from the URL.&quot;&quot;&quot;</span></div>
<div class="line">        <span class="keywordflow">pass</span> <span class="comment"># Each specific strategy must implement this</span></div>
</div><!-- fragment --><p>And then the specific implementations:</p>
<div class="fragment"><div class="line"><span class="comment"># Simplified from async_crawler_strategy.py</span></div>
<div class="line"><span class="keyword">from</span> playwright.async_api <span class="keyword">import</span> Page <span class="comment"># Playwright library for browser automation</span></div>
<div class="line"><span class="comment"># ... other imports</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>AsyncPlaywrightCrawlerStrategy(AsyncCrawlerStrategy):</div>
<div class="line">    <span class="comment"># ... (Initialization code to manage browsers)</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">async def </span>crawl(self, url: str, config: CrawlerRunConfig, **kwargs) -&gt; AsyncCrawlResponse:</div>
<div class="line">        <span class="comment"># Uses Playwright to:</span></div>
<div class="line">        <span class="comment"># 1. Get a browser page</span></div>
<div class="line">        <span class="comment"># 2. Navigate to the url (page.goto(url))</span></div>
<div class="line">        <span class="comment"># 3. Wait for content, run JS, etc.</span></div>
<div class="line">        <span class="comment"># 4. Get the final HTML (page.content())</span></div>
<div class="line">        <span class="comment"># 5. Optionally take screenshots, etc.</span></div>
<div class="line">        <span class="comment"># 6. Return an AsyncCrawlResponse</span></div>
<div class="line">        <span class="comment"># ... implementation details ...</span></div>
<div class="line">        <span class="keywordflow">pass</span></div>
</div><!-- fragment --><div class="fragment"><div class="line"><span class="comment"># Simplified from async_crawler_strategy.py</span></div>
<div class="line"><span class="keyword">import</span> aiohttp <span class="comment"># Library for making HTTP requests asynchronously</span></div>
<div class="line"><span class="comment"># ... other imports</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>AsyncHTTPCrawlerStrategy(AsyncCrawlerStrategy):</div>
<div class="line">    <span class="comment"># ... (Initialization code to manage HTTP sessions)</span></div>
<div class="line"> </div>
<div class="line">    <span class="keyword">async def </span>crawl(self, url: str, config: CrawlerRunConfig, **kwargs) -&gt; AsyncCrawlResponse:</div>
<div class="line">        <span class="comment"># Uses aiohttp to:</span></div>
<div class="line">        <span class="comment"># 1. Make an HTTP GET (or other method) request to the url</span></div>
<div class="line">        <span class="comment"># 2. Read the response body (HTML)</span></div>
<div class="line">        <span class="comment"># 3. Get response headers and status code</span></div>
<div class="line">        <span class="comment"># 4. Return an AsyncCrawlResponse</span></div>
<div class="line">        <span class="comment"># ... implementation details ...</span></div>
<div class="line">        <span class="keywordflow">pass</span></div>
</div><!-- fragment --><p>The key takeaway is that both strategies implement the same <code>crawl</code> method, allowing <code>AsyncWebCrawler</code> to use them interchangeably.</p>
<h2><a class="anchor" id="autotoc_md1387"></a>
Conclusion</h2>
<p>You've learned about <code>AsyncCrawlerStrategy</code>, the core concept defining <em>how</em> Crawl4AI fetches webpage content.</p>
<ul>
<li>It's like choosing a vehicle: a powerful browser (<code>AsyncPlaywrightCrawlerStrategy</code>, the default) or a fast, simple HTTP request (<code>AsyncHTTPCrawlerStrategy</code>).</li>
<li>This abstraction gives you flexibility to choose the right fetching method for your task.</li>
<li>You usually don't need to worry about it, as the default handles most modern websites well.</li>
</ul>
<p>Now that we understand how the raw content is fetched, the next step is to look at the main class that orchestrates the entire crawling process.</p>
<p><b>Next:</b> Let's dive into the <a class="el" href="../../d8/dc9/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_202__asyncwebcrawler.html">AsyncWebCrawler</a> itself!</p>
<hr  />
<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a> </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
