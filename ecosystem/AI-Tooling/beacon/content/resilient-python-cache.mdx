import { CommentSection } from '@/components/CommentSection'
import { Divider, Box, Space, Tabs, TabsList, TabsTab, TabsPanel, Code, Alert } from '@mantine/core'
import { IconInfoCircle } from '@tabler/icons-react'
import { PythonConfigGenerator } from '../components/cache/PythonConfigGenerator'
import { PythonQueryBuilder } from '../components/cache/PythonQueryBuilder'

{/* BEGIN AUTO_DOC: resilient-python-cache */}

# resilient-python-cache

`resilient-python-cache` is a library that *automatically keeps a local MongoDB database in sync* with a remote **ResilientDB**. It uses a dual-strategy of listening for *real-time push notifications* (via WebSocket) and periodically *pulling data in batches* (via HTTP) to ensure no data is missed. The library is built to be **resilient**, automatically handling connection drops and efficiently fetching large amounts of data.


```mermaid
flowchart TD
A0["`ResilientPythonCache` (The Sync Orchestrator)"]
A1["Configuration Models (`MongoConfig` & `ResilientDBConfig`)"]
A2["Dual-Mode Data Sync (HTTP & WebSocket)"]
A3["Resilient Connection Management"]
A4["Concurrent Batch Processing"]
A5["Event-Driven API (`AsyncIOEventEmitter`)"]
A0 -- "Is configured by" --> A1
A0 -- "Orchestrates" --> A2
A0 -- "Inherits from" --> A5
A2 -- "Relies on" --> A3
A2 -- "Uses" --> A4

```

`resilient-python-cache` is a Python library that provides a robust, real-time local cache for data from a ResilientDB instance. It is designed to solve the challenge of keeping a local data copy perfectly synchronized with a remote source, ensuring your application is both fast and fault-tolerant.

## Core Architecture: Dual-Mode Data Synchronization

To guarantee data is both fresh and complete, the library employs a dual-mode synchronization strategy, combining "push" and "pull" methods that run in parallel.

### The "Push" Method (WebSocket)

For real-time updates, the library maintains a persistent WebSocket connection to the ResilientDB server. When new data is committed, the server "pushes" an immediate notification to the cache, triggering a fetch of the new block. This ensures minimal latency and a highly responsive application.

### The "Pull" Method (HTTP)

To act as a safety net, the library also periodically "pulls" data from a standard HTTP endpoint. This recurring fetch requests any blocks created since the last check, guaranteeing that no data is ever missed, even if the WebSocket connection is temporarily interrupted.

### How They Work Together

The WebSocket provides speed, while the periodic HTTP fetch provides reliability. If a WebSocket notification is missed for any reason, the HTTP pull will catch the missing data on its next cycle. Both methods trigger the same underlying logic to fetch and store new blocks, ensuring consistency.

```python
# The WebSocket listener triggers a fetch upon receiving a message
async def connect_websocket(self):
    async with websockets.connect(self.ws_endpoint) as websocket:
        async for message in websocket:
            if "Update blocks" in message:
                # Trigger a fetch to get the new data
                await self.fetch_and_sync_new_blocks()

# The periodic fetch runs on a timer as a backup
async def start_periodic_fetch(self):
    while not self.is_closing:
        await self.fetch_and_sync_new_blocks()
        await asyncio.sleep(self.fetch_interval / 1000)
```

## Getting Started: The `ResilientPythonCache` Class

The `ResilientPythonCache` class is the central orchestrator that manages all synchronization logic. Think of it as a general manager for your local data cache; you configure it, start it, and it handles all background tasks automatically.

### Basic Usage

Using the library involves four straightforward steps:

1.  **Provide Configuration**: Define where to get data from (`ResilientDBConfig`) and where to store it (`MongoConfig`).
2.  **Instantiate the Cache**: Create an instance of `ResilientPythonCache` with your configurations.
3.  **Listen for Events**: Register handler functions for events like `data` or `error`.
4.  **Initialize**: Call the `await cache.initialize()` method to start the connection and synchronization processes.

```python
import asyncio
from resilient_python_cache import (
    ResilientPythonCache,
    MongoConfig,
    ResilientDBConfig
)

# 1. Configure databases
mongo_config = MongoConfig("mongodb://localhost:27017", "myAppDB", "transactions")
resilient_db_config = ResilientDBConfig("resilientdb://crow.resilientdb.com")

# 2. Create the cache instance
cache = ResilientPythonCache(mongo_config, resilient_db_config)

# 3. Listen for new data
cache.on("data", lambda blocks: print(f"Synced {len(blocks)} new blocks."))
cache.on("error", lambda err: print(f"An error occurred: {err}"))

# 4. Start the process
async def main():
    await cache.initialize()
    await asyncio.Future() # Keep the script running

asyncio.run(main())
```

When `initialize()` is called, it connects to MongoDB, performs an initial historical data sync, and then starts the dual-mode background tasks.

## Configuration

Configuration is handled through simple dataclass objects, separating connection details from your application logic.

### `MongoConfig`

This object specifies the details for your local MongoDB cache.

*   `uri`: The full connection string for your MongoDB server.
*   `db_name`: The name of the database to use.
*   `collection_name`: The name of the collection for storing blocks.

```python
mongo_config = MongoConfig(
    uri="mongodb://localhost:27017",
    db_name="myAppDB",
    collection_name="transactions"
)
```

### `ResilientDBConfig`

This object defines the connection details for the remote ResilientDB server.

*   `base_url`: The primary address of the ResilientDB node (e.g., `resilientdb://...`). The library derives the HTTP and WebSocket endpoints from this.
*   `fetch_interval` (optional): The interval in milliseconds for the HTTP pull mechanism (default: `10000`).
*   `reconnect_interval` (optional): The base delay in milliseconds for reconnection attempts (default: `2000`).

```python
resilient_db_config = ResilientDBConfig(
    base_url="resilientdb://crow.resilientdb.com",
    fetch_interval=5000 # Check every 5 seconds
)
```

## Interacting with the Cache: The Event-Driven API

Instead of forcing you to poll for status changes, `ResilientPythonCache` uses an event-driven model. You can subscribe handler functions to be called when specific events occur.

The primary events are:
*   `connected`: Fires when the WebSocket connection is established.
*   `data`: Fires after a new batch of blocks has been successfully saved to the local cache. The handler receives the list of new blocks.
*   `error`: Fires when a significant, non-recoverable error occurs.
*   `closed`: Fires after the cache connections have been gracefully closed via `cache.close()`.

```python
# Set up listeners before calling initialize()
cache.on("connected", lambda: print("Connection established!"))
cache.on("data", lambda blocks: update_dashboard(blocks))
cache.on("error", lambda err: log_critical_error(err))
```

## Fault Tolerance: Resilient Connection Management

The library is designed to be resilient to network disruptions. If the WebSocket connection drops, it will not crash the application. Instead, it automatically attempts to reconnect using an **exponential backoff** strategy.

*   The first attempt occurs after a short delay (e.g., 2 seconds).
*   If that fails, it waits for a longer period (e.g., 4 seconds), then 8, and so on.

This prevents the library from overwhelming the server with rapid reconnection requests while ensuring the connection is restored as soon as possible. During any disconnection, the periodic HTTP "pull" continues to run, ensuring your cache does not fall far behind.

## High-Performance Sync: Concurrent Batch Processing

When the cache starts for the first time, it may need to sync a large amount of historical data. To do this efficiently, it avoids fetching blocks one by one. Instead, it uses a high-performance strategy combining two techniques:

1.  **Batching**: It requests large ranges of blocks at once (e.g., 100 blocks per request).
2.  **Concurrency**: It runs multiple fetch operations in parallel to maximize throughput.

To prevent overwhelming the network or the remote server, this concurrency is managed by a **semaphore**, which limits the number of simultaneous HTTP requests. This allows the initial sync to complete in a fraction of the time a sequential approach would take.

---

Generated by [AI Codebase Knowledge Builder](https://github.com/The-Pocket/Tutorial-Codebase-Knowledge)

{/* END AUTO_DOC: resilient-python-cache */}

<Space h="xl" />
<Divider my="xl" label="Community Feedback" labelPosition="center" />

<Box mb="xl">
  <CommentSection
    pageTitle="Python Cache Documentation"
    pageUrl={typeof window !== 'undefined' ? window.location.href : ''}
    repoOwner="apache"
    repoName="incubator-resilientdb-resilient-python-cache"
    labels={['user-feedback', 'documentation', 'python-cache']}
    title="Questions or Feedback about the Python Cache?"
  />
</Box> 