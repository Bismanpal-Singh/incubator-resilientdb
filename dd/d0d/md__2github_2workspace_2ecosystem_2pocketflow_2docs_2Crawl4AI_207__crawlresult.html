#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
<!-- HTML header for doxygen 1.9.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.13.2"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ResilientDB: 07_crawlresult</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
  $(function() { init_search(); });
/* @license-end */
</script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen_html_style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../logo.png"/></td>
    <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <span id="MSearchSelect"                onmouseover="return searchBox.OnSearchSelectShow()"                onmouseout="return searchBox.OnSearchSelectHide()">&#160;</span>
          <input type="text" id="MSearchField" value="" placeholder="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.svg" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.13.2 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('dd/d0d/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_207__crawlresult.html','../../'); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">07_crawlresult</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="autotoc_md1424"></a>
autotoc_md1424</h2>
<p>layout: default title: "CrawlResult" parent: "Crawl4AI" </p>
<h2><a class="anchor" id="autotoc_md1425"></a>
nav_order: 7</h2>
<h1><a class="anchor" id="autotoc_md1426"></a>
Chapter 7: Understanding the Results - CrawlResult</h1>
<p>In the previous chapter, <a class="el" href="../../d1/d07/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_206__extractionstrategy.html">Chapter 6: Getting Specific Data - ExtractionStrategy</a>, we learned how to teach Crawl4AI to act like an analyst, extracting specific, structured data points from a webpage using an <code>ExtractionStrategy</code>. We've seen how Crawl4AI can fetch pages, clean them, filter them, and even extract precise information.</p>
<p>But after all that work, where does all the gathered information go? When you ask the <code>AsyncWebCrawler</code> to crawl a URL using <code>arun()</code>, what do you actually get back?</p>
<h2><a class="anchor" id="autotoc_md1427"></a>
What Problem Does <code>CrawlResult</code> Solve?</h2>
<p>Imagine you sent a research assistant to the library (a website) with a set of instructions: "Find this book (URL), make a clean copy of the relevant chapter (clean HTML/Markdown), list all the cited references (links), take photos of the illustrations (media), find the author and publication date (metadata), and maybe extract specific quotes (structured data)."</p>
<p>When the assistant returns, they wouldn't just hand you a single piece of paper. They'd likely give you a folder containing everything you asked for: the clean copy, the list of references, the photos, the metadata notes, and the extracted quotes, all neatly organized. They might also include a note if they encountered any problems (errors).</p>
<p><code>CrawlResult</code> is exactly this <b>final report folder</b> or <b>delivery package</b>. It's a single object that neatly contains <em>all</em> the information Crawl4AI gathered and processed for a specific URL during a crawl operation. Instead of getting lots of separate pieces of data back, you get one convenient container.</p>
<h2><a class="anchor" id="autotoc_md1428"></a>
What is <code>CrawlResult</code>?</h2>
<p><code>CrawlResult</code> is a Python object (specifically, a Pydantic model, which is like a super-powered dictionary) that acts as a data container. It holds the results of a single crawl task performed by <code>AsyncWebCrawler.arun()</code> or one of the results from <code>arun_many()</code>.</p>
<p>Think of it as a toolbox filled with different tools and information related to the crawled page.</p>
<p><b>Key Information Stored in <code>CrawlResult</code>:</b></p>
<ul>
<li><b><code>url</code> (string):</b> The original URL that was requested.</li>
<li><b><code>success</code> (boolean):</b> Did the crawl complete without critical errors? <code>True</code> if successful, <code>False</code> otherwise. <b>Always check this first!</b></li>
<li><b><code>html</code> (string):</b> The raw, original HTML source code fetched from the page.</li>
<li><b><code>cleaned_html</code> (string):</b> The HTML after initial cleaning by the <a class="el" href="../../df/d80/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_204__contentscrapingstrategy.html">ContentScrapingStrategy</a> (e.g., scripts, styles removed).</li>
<li><b><code>markdown</code> (object):</b> An object containing different Markdown representations of the content.<ul>
<li><code>markdown.raw_markdown</code>: Basic Markdown generated from <code>cleaned_html</code>.</li>
<li><code>markdown.fit_markdown</code>: Markdown generated <em>only</em> from content deemed relevant by a <a class="el" href="../../d2/d40/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_205__relevantcontentfilter.html">RelevantContentFilter</a> (if one was used). Might be empty if no filter was applied.</li>
<li><em>(Other fields like <code>markdown_with_citations</code> might exist)</em></li>
</ul>
</li>
<li><b><code>extracted_content</code> (string):</b> If you used an <a class="el" href="../../d1/d07/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_206__extractionstrategy.html">ExtractionStrategy</a>, this holds the extracted structured data, usually formatted as a JSON string. <code>None</code> if no extraction was performed or nothing was found.</li>
<li><b><code>metadata</code> (dictionary):</b> Information extracted from the page's metadata tags, like the page title (&lsquo;metadata['title&rsquo;]<code>), description, keywords, etc.</code></li>
<li><code> **</code>links&lt;tt&gt;(object):** Contains lists of links found on the page. *</li>
</ul>
<p>links.internal<code>: List of links pointing to the same website. *</code>links.external<code>: List of links pointing to other websites.</p><ul>
<li>**</li>
</ul>
<p></code>media&lt;tt&gt;(object):** Contains lists of media items found. *media.images<code>: List of images (</code><code>tags). *</code>media.videos<code>: List of videos (</code>&lt;video&gt;<code>tags).</p><ul>
<li>*(Other media types might be included)*</li>
</ul>
<p></code></p>
<p><code> **</code>screenshot&lt;tt&gt;(string):** If you requested a screenshot (screenshot=True<code>in</code>CrawlerRunConfig<code>), this holds the file path to the saved image.</code>None<code>otherwise.</p><ul>
<li>**</li>
</ul>
<p></code>pdf&lt;tt&gt;(bytes):** If you requested a PDF (pdf=True<code>in</code>CrawlerRunConfig<code>), this holds the PDF data as bytes.</code>None<code>otherwise. (Note: Previously might have been a path, now often bytes).</p><ul>
<li>**</li>
</ul>
<p></code>error_message&lt;tt&gt;(string):** Ifsuccess<code>is</code>False<code>, this field usually contains details about what went wrong.</p><ul>
<li>**</li>
</ul>
<p></code>status_code&lt;tt&gt;(integer):** The HTTP status code received from the server (e.g., 200 for OK, 404 for Not Found).</p><ul>
<li>**</li>
</ul>
<p>response_headers&lt;tt&gt;(dictionary):** The HTTP response headers sent by the server.</p><ul>
<li>**</li>
</ul>
<p>redirected_url` (string):** If the original URL redirected, this shows the final URL the crawler landed on.</p>
<h2><a class="anchor" id="autotoc_md1429"></a>
Accessing the <code>CrawlResult</code></h2>
<p>You get a <code>CrawlResult</code> object back every time you <code>await</code> a call to <code>crawler.arun()</code>:</p>
<div class="fragment"><div class="line"><span class="comment"># chapter7_example_1.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> AsyncWebCrawler</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        url = <span class="stringliteral">&quot;https://httpbin.org/html&quot;</span></div>
<div class="line">        print(f<span class="stringliteral">&quot;Crawling {url}...&quot;</span>)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># The &#39;arun&#39; method returns a CrawlResult object</span></div>
<div class="line">        result: CrawlResult = await crawler.arun(url=url) <span class="comment"># Type hint optional</span></div>
<div class="line"> </div>
<div class="line">        print(<span class="stringliteral">&quot;Crawl finished!&quot;</span>)</div>
<div class="line">        <span class="comment"># Now &#39;result&#39; holds all the information</span></div>
<div class="line">        print(f<span class="stringliteral">&quot;Result object type: {type(result)}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
<div class="ttc" id="anamespacemain_html"><div class="ttname"><a href="../../d2/dc1/namespacemain.html">main</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/dba/main_8py_source.html#l00001">main.py:1</a></div></div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ol type="1">
<li>We call <code>crawler.arun(url=url)</code>.</li>
<li>The <code>await</code> keyword pauses execution until the crawl is complete.</li>
<li>The value returned by <code>arun</code> is assigned to the <code>result</code> variable.</li>
<li>This <code>result</code> variable is our <code>CrawlResult</code> object.</li>
</ol>
<p>If you use <code>crawler.arun_many()</code>, it returns a list where each item is a <code>CrawlResult</code> object for one of the requested URLs (or an async generator if <code>stream=True</code>).</p>
<h2><a class="anchor" id="autotoc_md1430"></a>
Exploring the Attributes: Using the Toolbox</h2>
<p>Once you have the <code>result</code> object, you can access its attributes using dot notation (e.g., <code>result.success</code>, <code>result.markdown</code>).</p>
<p><b>1. Checking for Success (Most Important!)</b></p>
<p>Before you try to use any data, always check if the crawl was successful:</p>
<div class="fragment"><div class="line"><span class="comment"># chapter7_example_2.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> AsyncWebCrawler, CrawlResult <span class="comment"># Import CrawlResult for type hint</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        url = <span class="stringliteral">&quot;https://httpbin.org/html&quot;</span> <span class="comment"># A working URL</span></div>
<div class="line">        <span class="comment"># url = &quot;https://httpbin.org/status/404&quot; # Try this URL to see failure</span></div>
<div class="line">        result: CrawlResult = await crawler.arun(url=url)</div>
<div class="line"> </div>
<div class="line">        <span class="comment"># --- ALWAYS CHECK &#39;success&#39; FIRST! ---</span></div>
<div class="line">        <span class="keywordflow">if</span> result.success:</div>
<div class="line">            print(f<span class="stringliteral">&quot;✅ Successfully crawled: {result.url}&quot;</span>)</div>
<div class="line">            <span class="comment"># Now it&#39;s safe to access other attributes</span></div>
<div class="line">            print(f<span class="stringliteral">&quot;   Page Title: {result.metadata.get(&#39;title&#39;, &#39;N/A&#39;)}&quot;</span>)</div>
<div class="line">        <span class="keywordflow">else</span>:</div>
<div class="line">            print(f<span class="stringliteral">&quot;❌ Failed to crawl: {result.url}&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;   Error: {result.error_message}&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;   Status Code: {result.status_code}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ul>
<li>We use an <code>if result.success:</code> block.</li>
<li>If <code>True</code>, we proceed to access other data like <code>result.metadata</code>.</li>
<li>If <code>False</code>, we print the <code>result.error_message</code> and <code>result.status_code</code> to understand why it failed.</li>
</ul>
<p><b>2. Accessing Content (HTML, Markdown)</b></p>
<div class="fragment"><div class="line"><span class="comment"># chapter7_example_3.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> AsyncWebCrawler, CrawlResult</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        url = <span class="stringliteral">&quot;https://httpbin.org/html&quot;</span></div>
<div class="line">        result: CrawlResult = await crawler.arun(url=url)</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> result.success:</div>
<div class="line">            print(<span class="stringliteral">&quot;--- Content ---&quot;</span>)</div>
<div class="line">            <span class="comment"># Print the first 150 chars of raw HTML</span></div>
<div class="line">            print(f<span class="stringliteral">&quot;Raw HTML snippet: {result.html[:150]}...&quot;</span>)</div>
<div class="line"> </div>
<div class="line">            <span class="comment"># Access the raw markdown</span></div>
<div class="line">            <span class="keywordflow">if</span> result.markdown: <span class="comment"># Check if markdown object exists</span></div>
<div class="line">                 print(f<span class="stringliteral">&quot;Markdown snippet: {result.markdown.raw_markdown[:150]}...&quot;</span>)</div>
<div class="line">            <span class="keywordflow">else</span>:</div>
<div class="line">                 print(<span class="stringliteral">&quot;Markdown not generated.&quot;</span>)</div>
<div class="line">        <span class="keywordflow">else</span>:</div>
<div class="line">            print(f<span class="stringliteral">&quot;Crawl failed: {result.error_message}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ul>
<li>We access <code>result.html</code> for the original HTML.</li>
<li>We access <code>result.markdown.raw_markdown</code> for the main Markdown content. Note the two dots: <code>result.markdown</code> gives the <code>MarkdownGenerationResult</code> object, and <code>.raw_markdown</code> accesses the specific string within it. We also check <code>if result.markdown:</code> first, just in case markdown generation failed for some reason.</li>
</ul>
<p><b>3. Getting Metadata, Links, and Media</b></p>
<div class="fragment"><div class="line"><span class="comment"># chapter7_example_4.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> AsyncWebCrawler, CrawlResult</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        url = <span class="stringliteral">&quot;https://httpbin.org/links/10/0&quot;</span> <span class="comment"># A page with links</span></div>
<div class="line">        result: CrawlResult = await crawler.arun(url=url)</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> result.success:</div>
<div class="line">            print(<span class="stringliteral">&quot;--- Metadata &amp; Links ---&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;Title: {result.metadata.get(&#39;title&#39;, &#39;N/A&#39;)}&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;Found {len(result.links.internal)} internal links.&quot;</span>)</div>
<div class="line">            print(f<span class="stringliteral">&quot;Found {len(result.links.external)} external links.&quot;</span>)</div>
<div class="line">            <span class="keywordflow">if</span> result.links.internal:</div>
<div class="line">                print(f<span class="stringliteral">&quot;  First internal link text: &#39;{result.links.internal[0].text}&#39;&quot;</span>)</div>
<div class="line">            <span class="comment"># Similarly access result.media.images etc.</span></div>
<div class="line">        <span class="keywordflow">else</span>:</div>
<div class="line">            print(f<span class="stringliteral">&quot;Crawl failed: {result.error_message}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ul>
<li><code>result.metadata</code> is a dictionary; use <code>.<a class="el" href="../../d7/da6/pybind__kv__service_8cpp.html#abe6524afb3a69dc9a4c314e11f96f29f">get()</a></code> for safe access.</li>
<li><code>result.links</code> and <code>result.media</code> are objects containing lists (<code>internal</code>, <code>external</code>, <code>images</code>, etc.). We can check their lengths (<code>len()</code>) and access individual items by index (e.g., <code>[0]</code>).</li>
</ul>
<p><b>4. Checking for Extracted Data, Screenshots, PDFs</b></p>
<div class="fragment"><div class="line"><span class="comment"># chapter7_example_5.py</span></div>
<div class="line"><span class="keyword">import</span> asyncio</div>
<div class="line"><span class="keyword">import</span> json</div>
<div class="line"><span class="keyword">from</span> crawl4ai <span class="keyword">import</span> (</div>
<div class="line">    AsyncWebCrawler, CrawlResult, CrawlerRunConfig,</div>
<div class="line">    JsonCssExtractionStrategy <span class="comment"># Example extractor</span></div>
<div class="line">)</div>
<div class="line"> </div>
<div class="line"><span class="keyword">async def </span><a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>():</div>
<div class="line">    <span class="comment"># Define a simple extraction strategy (from Chapter 6)</span></div>
<div class="line">    schema = {<span class="stringliteral">&quot;baseSelector&quot;</span>: <span class="stringliteral">&quot;body&quot;</span>, <span class="stringliteral">&quot;fields&quot;</span>: [{<span class="stringliteral">&quot;name&quot;</span>: <span class="stringliteral">&quot;heading&quot;</span>, <span class="stringliteral">&quot;selector&quot;</span>: <span class="stringliteral">&quot;h1&quot;</span>, <span class="stringliteral">&quot;type&quot;</span>: <span class="stringliteral">&quot;text&quot;</span>}]}</div>
<div class="line">    extractor = JsonCssExtractionStrategy(schema=schema)</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># Configure the run to extract and take a screenshot</span></div>
<div class="line">    config = CrawlerRunConfig(</div>
<div class="line">        extraction_strategy=extractor,</div>
<div class="line">        screenshot=<span class="keyword">True</span></div>
<div class="line">    )</div>
<div class="line"> </div>
<div class="line">    <span class="keyword">async</span> <span class="keyword">with</span> AsyncWebCrawler() <span class="keyword">as</span> crawler:</div>
<div class="line">        url = <span class="stringliteral">&quot;https://httpbin.org/html&quot;</span></div>
<div class="line">        result: CrawlResult = await crawler.arun(url=url, config=config)</div>
<div class="line"> </div>
<div class="line">        <span class="keywordflow">if</span> result.success:</div>
<div class="line">            print(<span class="stringliteral">&quot;--- Extracted Data &amp; Media ---&quot;</span>)</div>
<div class="line">            <span class="comment"># Check if structured data was extracted</span></div>
<div class="line">            <span class="keywordflow">if</span> result.extracted_content:</div>
<div class="line">                print(<span class="stringliteral">&quot;Extracted Data found:&quot;</span>)</div>
<div class="line">                data = json.loads(result.extracted_content) <span class="comment"># Parse the JSON string</span></div>
<div class="line">                print(json.dumps(data, indent=2))</div>
<div class="line">            <span class="keywordflow">else</span>:</div>
<div class="line">                print(<span class="stringliteral">&quot;No structured data extracted.&quot;</span>)</div>
<div class="line"> </div>
<div class="line">            <span class="comment"># Check if a screenshot was taken</span></div>
<div class="line">            <span class="keywordflow">if</span> result.screenshot:</div>
<div class="line">                print(f<span class="stringliteral">&quot;Screenshot saved to: {result.screenshot}&quot;</span>)</div>
<div class="line">            <span class="keywordflow">else</span>:</div>
<div class="line">                print(<span class="stringliteral">&quot;Screenshot not taken.&quot;</span>)</div>
<div class="line"> </div>
<div class="line">            <span class="comment"># Check for PDF (would be bytes if requested and successful)</span></div>
<div class="line">            <span class="keywordflow">if</span> result.pdf:</div>
<div class="line">                 print(f<span class="stringliteral">&quot;PDF data captured ({len(result.pdf)} bytes).&quot;</span>)</div>
<div class="line">            <span class="keywordflow">else</span>:</div>
<div class="line">                 print(<span class="stringliteral">&quot;PDF not generated.&quot;</span>)</div>
<div class="line">        <span class="keywordflow">else</span>:</div>
<div class="line">            print(f<span class="stringliteral">&quot;Crawl failed: {result.error_message}&quot;</span>)</div>
<div class="line"> </div>
<div class="line"><span class="keywordflow">if</span> __name__ == <span class="stringliteral">&quot;__main__&quot;</span>:</div>
<div class="line">    asyncio.run(<a class="code hl_namespace" href="../../d2/dc1/namespacemain.html">main</a>())</div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ul>
<li>We check if <code>result.extracted_content</code> is not <code>None</code> or empty before trying to parse it as JSON.</li>
<li>We check if <code>result.screenshot</code> is not <code>None</code> to see if the file path exists.</li>
<li>We check if <code>result.pdf</code> is not <code>None</code> to see if the PDF data (bytes) was captured.</li>
</ul>
<h2><a class="anchor" id="autotoc_md1431"></a>
How is <code>CrawlResult</code> Created? (Under the Hood)</h2>
<p>You don't interact with the <code>CrawlResult</code> constructor directly. The <code>AsyncWebCrawler</code> creates it for you at the very end of the <code>arun</code> process, typically inside its internal <code>aprocess_html</code> method (or just before returning if fetching from cache).</p>
<p>Here's a simplified sequence:</p>
<ol type="1">
<li><b>Fetch:</b> <code>AsyncWebCrawler</code> calls the <a class="el" href="../../dc/d53/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_201__asynccrawlerstrategy.html">AsyncCrawlerStrategy</a> to get the raw <code>html</code>, <code>status_code</code>, <code>response_headers</code>, etc.</li>
<li><b>Scrape:</b> It passes the <code>html</code> to the <a class="el" href="../../df/d80/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_204__contentscrapingstrategy.html">ContentScrapingStrategy</a> to get <code>cleaned_html</code>, <code>links</code>, <code>media</code>, <code>metadata</code>.</li>
<li><b>Markdown:</b> It generates Markdown using the configured generator, possibly involving a <a class="el" href="../../d2/d40/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_205__relevantcontentfilter.html">RelevantContentFilter</a>, resulting in a <code>MarkdownGenerationResult</code> object.</li>
<li><b>Extract (Optional):</b> If an <a class="el" href="../../d1/d07/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_206__extractionstrategy.html">ExtractionStrategy</a> is configured, it runs it on the appropriate content (HTML or Markdown) to get <code>extracted_content</code>.</li>
<li><b>Screenshot/PDF (Optional):</b> If requested, the fetching strategy captures the <code>screenshot</code> path or <code>pdf</code> data.</li>
<li><b>Package:</b> <code>AsyncWebCrawler</code> gathers all these pieces (<code>url</code>, <code>html</code>, <code>cleaned_html</code>, the markdown object, <code>links</code>, <code>media</code>, <code>metadata</code>, <code>extracted_content</code>, <code>screenshot</code>, <code>pdf</code>, <code>success</code> status, <code>error_message</code>, etc.).</li>
<li><b>Instantiate:</b> It creates the <code>CrawlResult</code> object, passing all the gathered data into its constructor.</li>
<li><b>Return:</b> It returns this fully populated <code>CrawlResult</code> object to your code.</li>
</ol>
<h2><a class="anchor" id="autotoc_md1432"></a>
Code Glimpse (<code>models.py</code>)</h2>
<p>The <code>CrawlResult</code> is defined in the <code>crawl4ai/models.py</code> file. It uses Pydantic, a library that helps define data structures with type hints and validation. Here's a simplified view:</p>
<div class="fragment"><div class="line"><span class="comment"># Simplified from crawl4ai/models.py</span></div>
<div class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, HttpUrl</div>
<div class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List, Dict, Optional, Any</div>
<div class="line"> </div>
<div class="line"><span class="comment"># Other related models (simplified)</span></div>
<div class="line"><span class="keyword">class </span>MarkdownGenerationResult(BaseModel):</div>
<div class="line">    raw_markdown: str</div>
<div class="line">    fit_markdown: Optional[str] = <span class="keywordtype">None</span></div>
<div class="line">    <span class="comment"># ... other markdown fields ...</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>Links(BaseModel):</div>
<div class="line">    internal: List[Dict] = []</div>
<div class="line">    external: List[Dict] = []</div>
<div class="line"> </div>
<div class="line"><span class="keyword">class </span>Media(BaseModel):</div>
<div class="line">    images: List[Dict] = []</div>
<div class="line">    videos: List[Dict] = []</div>
<div class="line"> </div>
<div class="line"><span class="comment"># The main CrawlResult model</span></div>
<div class="line"><span class="keyword">class </span>CrawlResult(BaseModel):</div>
<div class="line">    url: str</div>
<div class="line">    html: str</div>
<div class="line">    success: bool</div>
<div class="line">    cleaned_html: Optional[str] = <span class="keywordtype">None</span></div>
<div class="line">    media: Media = Media() <span class="comment"># Use the Media model</span></div>
<div class="line">    links: Links = Links() <span class="comment"># Use the Links model</span></div>
<div class="line">    screenshot: Optional[str] = <span class="keywordtype">None</span></div>
<div class="line">    pdf: Optional[bytes] = <span class="keywordtype">None</span></div>
<div class="line">    <span class="comment"># Uses a private attribute and property for markdown for compatibility</span></div>
<div class="line">    _markdown: Optional[MarkdownGenerationResult] = <span class="keywordtype">None</span> <span class="comment"># Actual storage</span></div>
<div class="line">    extracted_content: Optional[str] = <span class="keywordtype">None</span> <span class="comment"># JSON string</span></div>
<div class="line">    metadata: Optional[Dict[str, Any]] = <span class="keywordtype">None</span></div>
<div class="line">    error_message: Optional[str] = <span class="keywordtype">None</span></div>
<div class="line">    status_code: Optional[int] = <span class="keywordtype">None</span></div>
<div class="line">    response_headers: Optional[Dict[str, str]] = <span class="keywordtype">None</span></div>
<div class="line">    redirected_url: Optional[str] = <span class="keywordtype">None</span></div>
<div class="line">    <span class="comment"># ... other fields like session_id, ssl_certificate ...</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment"># Custom property to access markdown data</span></div>
<div class="line">    <span class="preprocessor">@property</span></div>
<div class="line">    <span class="keyword">def </span>markdown(self) -&gt; Optional[MarkdownGenerationResult]:</div>
<div class="line">        <span class="keywordflow">return</span> self._markdown</div>
<div class="line"> </div>
<div class="line">    <span class="comment"># Configuration for Pydantic</span></div>
<div class="line">    <span class="keyword">class </span>Config:</div>
<div class="line">        arbitrary_types_allowed = <span class="keyword">True</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment"># Custom init and model_dump might exist for backward compatibility handling</span></div>
<div class="line">    <span class="comment"># ... (omitted for simplicity) ...</span></div>
</div><!-- fragment --><p><b>Explanation:</b></p>
<ul>
<li>It's defined as a <code>class CrawlResult(BaseModel):</code>.</li>
<li>Each attribute (like <code>url</code>, <code>html</code>, <code>success</code>) is defined with a type hint (like <code>str</code>, <code>bool</code>, <code>Optional[str]</code>). <code>Optional[str]</code> means the field can be a string or <code>None</code>.</li>
<li>Some attributes are themselves complex objects defined by other Pydantic models (like <code>media: Media</code>, <code>links: Links</code>).</li>
<li>The <code>markdown</code> field uses a common pattern (property wrapping a private attribute) to provide the <code>MarkdownGenerationResult</code> object while maintaining some backward compatibility. You access it simply as <code>result.markdown</code>.</li>
</ul>
<h2><a class="anchor" id="autotoc_md1433"></a>
Conclusion</h2>
<p>You've now met the <code>CrawlResult</code> object – the final, comprehensive report delivered by Crawl4AI after processing a URL.</p>
<ul>
<li>It acts as a <b>container</b> holding all gathered information (HTML, Markdown, metadata, links, media, extracted data, errors, etc.).</li>
<li>It's the <b>return value</b> of <code>AsyncWebCrawler.arun()</code> and <code>arun_many()</code>.</li>
<li>The most crucial attribute is <b><code>success</code> (boolean)</b>, which you should always check first.</li>
<li>You can easily <b>access</b> all the different pieces of information using dot notation (e.g., &lsquo;result.metadata['title&rsquo;]<code>,</code>result.markdown.raw_markdown<code>,</code>result.links.external`).</li>
</ul>
<p>Understanding the <code>CrawlResult</code> is key to effectively using the information Crawl4AI provides.</p>
<p>So far, we've focused on crawling single pages or lists of specific URLs. But what if you want to start at one page and automatically discover and crawl linked pages, exploring a website more deeply?</p>
<p><b>Next:</b> Let's explore how to perform multi-page crawls with <a class="el" href="../../d3/da3/md__2github_2workspace_2ecosystem_2pocketflow_2docs_2Crawl4AI_208__deepcrawlstrategy.html">Chapter 8: Exploring Websites - DeepCrawlStrategy</a>.</p>
<hr  />
<p>Generated by <a href="https://github.com/The-Pocket/Tutorial-Codebase-Knowledge">AI Codebase Knowledge Builder</a> </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.13.2 </li>
  </ul>
</div>
</body>
</html>
